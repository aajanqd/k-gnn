{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aqd215/k-gnn/examples\n"
     ]
    }
   ],
   "source": [
    "cd /scratch/aqd215/k-gnn/examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import QM9\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import NNConv\n",
    "from k_gnn import GraphConv, DataLoader, avg_pool\n",
    "from k_gnn import ConnectedThreeMalkin\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFilter(object):\n",
    "    def __call__(self, data):\n",
    "        return data.num_nodes > 6  # Remove graphs with less than 6 nodes.\n",
    "\n",
    "\n",
    "class MyPreTransform(object):\n",
    "    def __call__(self, data):\n",
    "        x = data.x\n",
    "        data.x = data.x[:, :5]\n",
    "        data = ConnectedThreeMalkin()(data)\n",
    "        data.x = x\n",
    "        return data\n",
    "\n",
    "\n",
    "class MyTransform(object):\n",
    "    def __call__(self, data):\n",
    "        data.y = data.y[:, 0]  # Specify target: 0 = mu\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 0\n",
    "path = osp.join(osp.dirname(osp.realpath(\"__file__\")), '..', 'data', '1-3-QM9')\n",
    "dataset = QM9(\n",
    "    path,\n",
    "    transform=T.Compose([MyTransform(), T.Distance()]),\n",
    "    pre_transform=MyPreTransform(),\n",
    "    pre_filter=MyFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(assignment_index_3=[2, 13144659], edge_attr=[4823298, 4], edge_index=[2, 4823298], edge_index_3=[2, 1244888], idx=[129410], iso_type_3=[4381553], name=[129410], pos=[2333506, 3], x=[2333506, 13], y=[129410, 19], z=[2333506])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  6,   6,   6,  ..., 131, 131, 126]), torch.Size([4381553]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.iso_type_3, dataset.data.iso_type_3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,   2,   6,   7,   8,  12,  13,  31,  32,  33,  34,  37,  38,  39,\n",
       "         43,  44,  49,  62,  63,  68, 126, 127, 131, 132, 133, 137, 138, 156,\n",
       "        157, 158, 159, 162, 163, 164, 168, 169, 174, 187, 188, 193])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(dataset.data.iso_type_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1,   2,   6,   7,   8,  12,  13,  31,  32,  33,  34,  37,  38,  39,\n",
       "          43,  44,  49,  62,  63,  68, 126, 127, 131, 132, 133, 137, 138, 156,\n",
       "         157, 158, 159, 162, 163, 164, 168, 169, 174, 187, 188, 193]),\n",
       " tensor([ 2,  2,  2,  ..., 22, 22, 20]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(dataset.data.iso_type_3, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2,  2,  2,  ..., 22, 22, 20]), torch.Size([4381553]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(dataset.data.iso_type_3, True, True)[1], torch.unique(dataset.data.iso_type_3, True, True)[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data.iso_type_3 = torch.unique(dataset.data.iso_type_3, True, True)[1]\n",
    "num_i_3 = dataset.data.iso_type_3.max().item() + 1\n",
    "dataset.data.iso_type_3 = F.one_hot(\n",
    "    dataset.data.iso_type_3, num_classes=num_i_3).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset[2:3], batch_size=64)\n",
    "val_loader = DataLoader(dataset[1:2], batch_size=64)\n",
    "train_loader = DataLoader(dataset[:1], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(assignment_index_3=[2, 27], batch=[7], batch_3=[9], edge_attr=[12, 5], edge_index=[2, 12], edge_index_3=[2, 0], idx=[1], iso_type_3=[9, 40], name=[1], pos=[7, 3], x=[7, 13], y=[1], z=[7]) \n",
      " tensor([[0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 0., 1., 3.],\n",
      "        [0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 8., 1., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]) \n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 0.7237],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 0.7275],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 0.7275],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.7984],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 0.7396],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.7984],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 0.7237],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 0.7275],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 0.7275],\n",
      "        [1.0000, 0.0000, 0.0000, 0.0000, 0.7396]]) \n",
      " tensor([[0, 0, 0, 0, 1, 1, 1, 2, 3, 4, 5, 6],\n",
      "        [1, 3, 4, 5, 0, 2, 6, 1, 0, 0, 0, 1]]) \n",
      " tensor([2.5682])\n"
     ]
    }
   ],
   "source": [
    "for data in test_loader:\n",
    "    print(data, '\\n', data.x, '\\n', data.edge_attr, '\\n', data.edge_index, '\\n', data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtual Env py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
