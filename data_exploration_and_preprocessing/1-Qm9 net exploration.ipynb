{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aqd215/k-gnn/examples\n"
     ]
    }
   ],
   "source": [
    "cd /scratch/aqd215/k-gnn/examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import QM9\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import NNConv\n",
    "from k_gnn import GraphConv, DataLoader, avg_pool\n",
    "from k_gnn import ConnectedThreeMalkin\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFilter(object):\n",
    "    def __call__(self, data):\n",
    "        return data.num_nodes > 6  # Remove graphs with less than 6 nodes.\n",
    "\n",
    "\n",
    "class MyTransform(object):\n",
    "    def __call__(self, data):\n",
    "        data.y = data.y[:, 0]  # Specify target: 0 = mu\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 0\n",
    "path = osp.join(osp.dirname(osp.realpath(\"__file__\")), '..', 'data', '1-QM9')\n",
    "dataset = QM9(path, transform=T.Compose([MyTransform()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[4823498, 4], edge_index=[2, 4823498], idx=[129433], name=[129433], pos=[2333625, 3], x=[2333625, 13], y=[129433, 19], z=[2333625])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset[2:3], batch_size=64)\n",
    "val_loader = DataLoader(dataset[1:2], batch_size=64)\n",
    "train_loader = DataLoader(dataset[:1], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[3], edge_attr=[4, 4], edge_index=[2, 4], idx=[1], name=[1], pos=[3, 3], x=[3, 13], y=[1], z=[3]) \n",
      " tensor([[0., 0., 0., 1., 0., 8., 0., 0., 0., 0., 0., 1., 2.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]) \n",
      " tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]) \n",
      " tensor([[0, 0, 1, 2],\n",
      "        [1, 2, 0, 0]]) \n",
      " tensor([1.8511])\n"
     ]
    }
   ],
   "source": [
    "for data in test_loader:\n",
    "    print(data, '\\n', data.x, '\\n', data.edge_attr, '\\n', data.edge_index, '\\n', data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        M_in, M_out = 37,64 #data.num_features, 32 # \n",
    "        nn1 = Sequential(Linear(4, 128), ReLU(), Linear(128, M_in * M_out))\n",
    "        self.conv1 = NNConv(M_in, M_out, nn1)\n",
    "\n",
    "        M_in, M_out = M_out, 64\n",
    "        nn2 = Sequential(Linear(4, 128), ReLU(), Linear(128, M_in * M_out))\n",
    "        self.conv2 = NNConv(M_in, M_out, nn2)\n",
    "\n",
    "        M_in, M_out = M_out, 64\n",
    "        nn3 = Sequential(Linear(4, 128), ReLU(), Linear(128, M_in * M_out))\n",
    "        self.conv3 = NNConv(M_in, M_out, nn3)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(64, 32)\n",
    "        self.fc2 = torch.nn.Linear(32, 16)\n",
    "        self.fc3 = torch.nn.Linear(16, 1)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x = F.elu(self.conv1(x, data.edge_index, data.edge_attr))\n",
    "        x = F.elu(self.conv2(x, data.edge_index, data.edge_attr))\n",
    "        x = F.elu(self.conv3(x, data.edge_index, data.edge_attr))\n",
    "\n",
    "#         x = scatter_mean(x, data.batch, dim=0)\n",
    "\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x.view(-1)\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "#             print(m)\n",
    "            if isinstance(m, Sequential):\n",
    "                for elem in m:\n",
    "                    if isinstance(elem, Linear):\n",
    "                        torch.nn.init.kaiming_uniform_(elem.weight)\n",
    "            elif isinstance(m, Linear):\n",
    "                torch.nn.init.kaiming_uniform_(elem.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.7, patience=5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data.x = torch.tensor([[7., 0., 0., 1., 0., 0., 0., 0., 0., 4., 0., 0., 0., 1., 0., 0., 0., 0.,0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,0.],[6., 0., 1., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0., 1., 0., 0., 0., 0.,0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,0.],[6., 0., 1., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0., 1., 0., 0., 0., 0.,0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,0.],[7., 0., 0., 1., 0., 0., 0., 0., 0., 3., 0., 0., 1., 0., 0., 0., 0., 0.,0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,0.],[6., 0., 1., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0., 1., 0., 0., 0., 0.,0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,0.],[6., 0., 1., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0., 1., 0., 0., 0., 0.,0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,0.],[6., 0., 1., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0., 1., 0., 0., 0., 0.,0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,0.],[8., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[6., 0., 1., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0., 1., 0., 0., 0., 0.,0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,0.],[6., 0., 1., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0., 1., 0., 0., 0., 0.,0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,0.],[6., 0., 1., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0., 1., 0., 0., 0., 0.,0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.],[1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.]])\n",
    "        data.edge_attr = torch.tensor([[0., 1., 0., 0.],[0., 1., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.],[1., 0., 0., 0.]])\n",
    "        data.edge_index = torch.tensor([[ 0,  1,  4,  5,  4,  6,  1,  2,  0,  7,  2,  3,  2,  8,  3,  4,  2,  9,4,  0,  3, 10,  1, 11,  5, 12,  5, 13,  5, 14,  6, 15,  6, 16,  6, 17,8, 18,  8, 19,  8, 20,  9, 21,  9, 22,  9, 23, 10, 24, 10, 25, 10, 26],[ 1,  0,  5,  4,  6,  4,  2,  1,  7,  0,  3,  2,  8,  2,  4,  3,  9,  2,0,  4, 10,  3, 11,  1, 12,  5, 13,  5, 14,  5, 15,  6, 16,  6, 17,  6,18,  8, 19,  8, 20,  8, 21,  9, 22,  9, 23,  9, 24, 10, 25, 10, 26, 10]])\n",
    "        data.y = torch.tensor([0.0000,132.1000,60.5000,0.0000,90.0000,23.5000,23.5000,0.0000,23.3000,23.3000,26.1000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000])\n",
    "        \n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.mse_loss(model(data), data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        error += ((model(data) * std[target].cuda()) -\n",
    "                  (data.y * std[target].cuda())).abs().sum().item()  # MAE\n",
    "    return error / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, LR: 0.001000, Loss: 29229.7460938\n",
      "Epoch: 002, LR: 0.001000, Loss: 865.3693848\n",
      "Epoch: 003, LR: 0.001000, Loss: 1320.8010254\n",
      "Epoch: 004, LR: 0.001000, Loss: 801.1968994\n",
      "Epoch: 005, LR: 0.001000, Loss: 908.9588623\n",
      "Epoch: 006, LR: 0.001000, Loss: 804.7210083\n",
      "Epoch: 007, LR: 0.001000, Loss: 621.3265991\n",
      "Epoch: 008, LR: 0.001000, Loss: 804.3777466\n",
      "Epoch: 009, LR: 0.001000, Loss: 563.8712769\n",
      "Epoch: 010, LR: 0.001000, Loss: 551.7028809\n",
      "Epoch: 011, LR: 0.001000, Loss: 630.4744263\n",
      "Epoch: 012, LR: 0.001000, Loss: 566.6524048\n",
      "Epoch: 013, LR: 0.001000, Loss: 506.1747742\n",
      "Epoch: 014, LR: 0.001000, Loss: 546.0111694\n",
      "Epoch: 015, LR: 0.001000, Loss: 474.7767029\n",
      "Epoch: 016, LR: 0.001000, Loss: 473.9577942\n",
      "Epoch: 017, LR: 0.001000, Loss: 471.2495728\n",
      "Epoch: 018, LR: 0.001000, Loss: 441.9447021\n",
      "Epoch: 019, LR: 0.001000, Loss: 453.9951782\n",
      "Epoch: 020, LR: 0.001000, Loss: 414.0980225\n",
      "Epoch: 021, LR: 0.001000, Loss: 390.5586243\n",
      "Epoch: 022, LR: 0.001000, Loss: 396.9231567\n",
      "Epoch: 023, LR: 0.001000, Loss: 366.2993469\n",
      "Epoch: 024, LR: 0.001000, Loss: 355.9234924\n",
      "Epoch: 025, LR: 0.001000, Loss: 337.0683899\n",
      "Epoch: 026, LR: 0.001000, Loss: 297.6309814\n",
      "Epoch: 027, LR: 0.001000, Loss: 297.2132263\n",
      "Epoch: 028, LR: 0.001000, Loss: 259.7332764\n",
      "Epoch: 029, LR: 0.001000, Loss: 236.8254700\n",
      "Epoch: 030, LR: 0.001000, Loss: 217.5399170\n",
      "Epoch: 031, LR: 0.001000, Loss: 186.3945160\n",
      "Epoch: 032, LR: 0.001000, Loss: 173.9753113\n",
      "Epoch: 033, LR: 0.001000, Loss: 157.4291840\n",
      "Epoch: 034, LR: 0.001000, Loss: 146.1541138\n",
      "Epoch: 035, LR: 0.001000, Loss: 132.6084442\n",
      "Epoch: 036, LR: 0.001000, Loss: 122.4866791\n",
      "Epoch: 037, LR: 0.001000, Loss: 117.1695404\n",
      "Epoch: 038, LR: 0.001000, Loss: 109.7858887\n",
      "Epoch: 039, LR: 0.001000, Loss: 106.5679169\n",
      "Epoch: 040, LR: 0.001000, Loss: 103.0749893\n",
      "Epoch: 041, LR: 0.001000, Loss: 102.0288086\n",
      "Epoch: 042, LR: 0.001000, Loss: 100.3851318\n",
      "Epoch: 043, LR: 0.001000, Loss: 100.4926224\n",
      "Epoch: 044, LR: 0.001000, Loss: 97.6863556\n",
      "Epoch: 045, LR: 0.001000, Loss: 98.3020172\n",
      "Epoch: 046, LR: 0.001000, Loss: 96.0715790\n",
      "Epoch: 047, LR: 0.001000, Loss: 94.1327591\n",
      "Epoch: 048, LR: 0.001000, Loss: 89.5243988\n",
      "Epoch: 049, LR: 0.001000, Loss: 85.5339127\n",
      "Epoch: 050, LR: 0.001000, Loss: 87.2811356\n",
      "Epoch: 051, LR: 0.001000, Loss: 85.3788605\n",
      "Epoch: 052, LR: 0.001000, Loss: 80.8005295\n",
      "Epoch: 053, LR: 0.001000, Loss: 78.4852219\n",
      "Epoch: 054, LR: 0.001000, Loss: 77.8339844\n",
      "Epoch: 055, LR: 0.001000, Loss: 74.7731857\n",
      "Epoch: 056, LR: 0.001000, Loss: 73.4656525\n",
      "Epoch: 057, LR: 0.001000, Loss: 71.0922012\n",
      "Epoch: 058, LR: 0.001000, Loss: 66.4657516\n",
      "Epoch: 059, LR: 0.001000, Loss: 63.5555077\n",
      "Epoch: 060, LR: 0.001000, Loss: 61.8635635\n",
      "Epoch: 061, LR: 0.001000, Loss: 59.6362915\n",
      "Epoch: 062, LR: 0.001000, Loss: 56.3778610\n",
      "Epoch: 063, LR: 0.001000, Loss: 52.5899239\n",
      "Epoch: 064, LR: 0.001000, Loss: 49.9618912\n",
      "Epoch: 065, LR: 0.001000, Loss: 47.7152557\n",
      "Epoch: 066, LR: 0.001000, Loss: 45.6318245\n",
      "Epoch: 067, LR: 0.001000, Loss: 41.4626961\n",
      "Epoch: 068, LR: 0.001000, Loss: 39.0002518\n",
      "Epoch: 069, LR: 0.001000, Loss: 36.7654724\n",
      "Epoch: 070, LR: 0.001000, Loss: 32.9310226\n",
      "Epoch: 071, LR: 0.001000, Loss: 30.2045403\n",
      "Epoch: 072, LR: 0.001000, Loss: 28.7792702\n",
      "Epoch: 073, LR: 0.001000, Loss: 26.0078964\n",
      "Epoch: 074, LR: 0.001000, Loss: 26.8747063\n",
      "Epoch: 075, LR: 0.001000, Loss: 25.4095345\n",
      "Epoch: 076, LR: 0.001000, Loss: 20.7186909\n",
      "Epoch: 077, LR: 0.001000, Loss: 21.5769539\n",
      "Epoch: 078, LR: 0.001000, Loss: 19.3051987\n",
      "Epoch: 079, LR: 0.001000, Loss: 16.8883076\n",
      "Epoch: 080, LR: 0.001000, Loss: 16.5428123\n",
      "Epoch: 081, LR: 0.001000, Loss: 15.3739138\n",
      "Epoch: 082, LR: 0.001000, Loss: 14.2260313\n",
      "Epoch: 083, LR: 0.001000, Loss: 13.7135286\n",
      "Epoch: 084, LR: 0.001000, Loss: 13.4698181\n",
      "Epoch: 085, LR: 0.001000, Loss: 12.9465446\n",
      "Epoch: 086, LR: 0.001000, Loss: 12.6718273\n",
      "Epoch: 087, LR: 0.001000, Loss: 13.1170244\n",
      "Epoch: 088, LR: 0.001000, Loss: 14.0013790\n",
      "Epoch: 089, LR: 0.001000, Loss: 15.2845087\n",
      "Epoch: 090, LR: 0.001000, Loss: 15.9307222\n",
      "Epoch: 091, LR: 0.001000, Loss: 15.1443329\n",
      "Epoch: 092, LR: 0.001000, Loss: 12.9377937\n",
      "Epoch: 093, LR: 0.001000, Loss: 9.6875238\n",
      "Epoch: 094, LR: 0.001000, Loss: 7.0232091\n",
      "Epoch: 095, LR: 0.001000, Loss: 6.4408774\n",
      "Epoch: 096, LR: 0.001000, Loss: 7.5372982\n",
      "Epoch: 097, LR: 0.001000, Loss: 8.6362581\n",
      "Epoch: 098, LR: 0.001000, Loss: 8.3403311\n",
      "Epoch: 099, LR: 0.001000, Loss: 6.8520169\n",
      "Epoch: 100, LR: 0.001000, Loss: 5.3272119\n",
      "Epoch: 101, LR: 0.001000, Loss: 4.7351384\n",
      "Epoch: 102, LR: 0.001000, Loss: 5.0925179\n",
      "Epoch: 103, LR: 0.001000, Loss: 5.9187794\n",
      "Epoch: 104, LR: 0.001000, Loss: 6.3490968\n",
      "Epoch: 105, LR: 0.001000, Loss: 5.2419863\n",
      "Epoch: 106, LR: 0.001000, Loss: 4.2309518\n",
      "Epoch: 107, LR: 0.001000, Loss: 3.8028576\n",
      "Epoch: 108, LR: 0.001000, Loss: 4.0761433\n",
      "Epoch: 109, LR: 0.001000, Loss: 4.0440764\n",
      "Epoch: 110, LR: 0.001000, Loss: 3.4688570\n",
      "Epoch: 111, LR: 0.001000, Loss: 3.2207315\n",
      "Epoch: 112, LR: 0.001000, Loss: 3.3812358\n",
      "Epoch: 113, LR: 0.001000, Loss: 3.2630451\n",
      "Epoch: 114, LR: 0.001000, Loss: 2.9537897\n",
      "Epoch: 115, LR: 0.001000, Loss: 2.6648488\n",
      "Epoch: 116, LR: 0.001000, Loss: 2.6904128\n",
      "Epoch: 117, LR: 0.001000, Loss: 2.8872089\n",
      "Epoch: 118, LR: 0.001000, Loss: 2.7760427\n",
      "Epoch: 119, LR: 0.001000, Loss: 2.5528107\n",
      "Epoch: 120, LR: 0.001000, Loss: 2.2069654\n",
      "Epoch: 121, LR: 0.001000, Loss: 2.0663683\n",
      "Epoch: 122, LR: 0.001000, Loss: 2.1669605\n",
      "Epoch: 123, LR: 0.001000, Loss: 2.3317258\n",
      "Epoch: 124, LR: 0.001000, Loss: 2.5011737\n",
      "Epoch: 125, LR: 0.001000, Loss: 2.2558239\n",
      "Epoch: 126, LR: 0.001000, Loss: 1.9376577\n",
      "Epoch: 127, LR: 0.001000, Loss: 1.6002051\n",
      "Epoch: 128, LR: 0.001000, Loss: 1.5784543\n",
      "Epoch: 129, LR: 0.001000, Loss: 1.7035245\n",
      "Epoch: 130, LR: 0.001000, Loss: 1.7613204\n",
      "Epoch: 131, LR: 0.001000, Loss: 1.8665788\n",
      "Epoch: 132, LR: 0.001000, Loss: 1.8624668\n",
      "Epoch: 133, LR: 0.001000, Loss: 1.9800011\n",
      "Epoch: 134, LR: 0.001000, Loss: 1.9501289\n",
      "Epoch: 135, LR: 0.001000, Loss: 2.0570290\n",
      "Epoch: 136, LR: 0.001000, Loss: 1.8496048\n",
      "Epoch: 137, LR: 0.001000, Loss: 1.7456959\n",
      "Epoch: 138, LR: 0.001000, Loss: 1.3328599\n",
      "Epoch: 139, LR: 0.001000, Loss: 0.9570186\n",
      "Epoch: 140, LR: 0.001000, Loss: 0.9295596\n",
      "Epoch: 141, LR: 0.001000, Loss: 1.1704501\n",
      "Epoch: 142, LR: 0.001000, Loss: 1.7326736\n",
      "Epoch: 143, LR: 0.001000, Loss: 2.1916418\n",
      "Epoch: 144, LR: 0.001000, Loss: 3.1238770\n",
      "Epoch: 145, LR: 0.001000, Loss: 3.6362386\n",
      "Epoch: 146, LR: 0.001000, Loss: 4.7078514\n",
      "Epoch: 147, LR: 0.001000, Loss: 4.1945500\n",
      "Epoch: 148, LR: 0.001000, Loss: 2.3903885\n",
      "Epoch: 149, LR: 0.001000, Loss: 0.8688964\n",
      "Epoch: 150, LR: 0.001000, Loss: 0.7056899\n",
      "Epoch: 151, LR: 0.001000, Loss: 1.6474214\n",
      "Epoch: 152, LR: 0.001000, Loss: 2.7691264\n",
      "Epoch: 153, LR: 0.001000, Loss: 4.4998207\n",
      "Epoch: 154, LR: 0.001000, Loss: 5.1297450\n",
      "Epoch: 155, LR: 0.001000, Loss: 6.1546984\n",
      "Epoch: 156, LR: 0.001000, Loss: 6.8640714\n",
      "Epoch: 157, LR: 0.001000, Loss: 5.6781960\n",
      "Epoch: 158, LR: 0.001000, Loss: 4.3506351\n",
      "Epoch: 159, LR: 0.001000, Loss: 1.8081064\n",
      "Epoch: 160, LR: 0.001000, Loss: 1.2560173\n",
      "Epoch: 161, LR: 0.001000, Loss: 2.0702386\n",
      "Epoch: 162, LR: 0.001000, Loss: 2.9716516\n",
      "Epoch: 163, LR: 0.001000, Loss: 3.9716249\n",
      "Epoch: 164, LR: 0.001000, Loss: 3.7315245\n",
      "Epoch: 165, LR: 0.001000, Loss: 1.9637694\n",
      "Epoch: 166, LR: 0.001000, Loss: 0.9044076\n",
      "Epoch: 167, LR: 0.001000, Loss: 0.8534588\n",
      "Epoch: 168, LR: 0.001000, Loss: 1.2439684\n",
      "Epoch: 169, LR: 0.001000, Loss: 2.0731723\n",
      "Epoch: 170, LR: 0.001000, Loss: 2.4220417\n",
      "Epoch: 171, LR: 0.001000, Loss: 1.7533209\n",
      "Epoch: 172, LR: 0.001000, Loss: 0.9899650\n",
      "Epoch: 173, LR: 0.001000, Loss: 0.5911771\n",
      "Epoch: 174, LR: 0.001000, Loss: 0.4755566\n",
      "Epoch: 175, LR: 0.001000, Loss: 0.8306267\n",
      "Epoch: 176, LR: 0.001000, Loss: 1.3218429\n",
      "Epoch: 177, LR: 0.001000, Loss: 1.5136762\n",
      "Epoch: 178, LR: 0.001000, Loss: 1.5155890\n",
      "Epoch: 179, LR: 0.001000, Loss: 1.3672707\n",
      "Epoch: 180, LR: 0.001000, Loss: 0.9010701\n",
      "Epoch: 181, LR: 0.001000, Loss: 0.4779778\n",
      "Epoch: 182, LR: 0.001000, Loss: 0.2958413\n",
      "Epoch: 183, LR: 0.001000, Loss: 0.2014511\n",
      "Epoch: 184, LR: 0.001000, Loss: 0.2706086\n",
      "Epoch: 185, LR: 0.001000, Loss: 0.5048929\n",
      "Epoch: 186, LR: 0.001000, Loss: 0.6955120\n",
      "Epoch: 187, LR: 0.001000, Loss: 0.8278763\n",
      "Epoch: 188, LR: 0.001000, Loss: 0.9340504\n",
      "Epoch: 189, LR: 0.001000, Loss: 0.9078754\n",
      "Epoch: 190, LR: 0.001000, Loss: 0.8021048\n",
      "Epoch: 191, LR: 0.001000, Loss: 0.7180863\n",
      "Epoch: 192, LR: 0.001000, Loss: 0.5697885\n",
      "Epoch: 193, LR: 0.001000, Loss: 0.4205058\n",
      "Epoch: 194, LR: 0.001000, Loss: 0.3286413\n",
      "Epoch: 195, LR: 0.001000, Loss: 0.2398111\n",
      "Epoch: 196, LR: 0.001000, Loss: 0.1654761\n",
      "Epoch: 197, LR: 0.001000, Loss: 0.1354139\n",
      "Epoch: 198, LR: 0.001000, Loss: 0.1036886\n",
      "Epoch: 199, LR: 0.001000, Loss: 0.0746735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, LR: 0.001000, Loss: 0.0700615\n",
      "Epoch: 201, LR: 0.001000, Loss: 0.0598089\n",
      "Epoch: 202, LR: 0.001000, Loss: 0.0491872\n",
      "Epoch: 203, LR: 0.001000, Loss: 0.0533745\n",
      "Epoch: 204, LR: 0.001000, Loss: 0.0503556\n",
      "Epoch: 205, LR: 0.001000, Loss: 0.0477580\n",
      "Epoch: 206, LR: 0.001000, Loss: 0.0583296\n",
      "Epoch: 207, LR: 0.001000, Loss: 0.0667039\n",
      "Epoch: 208, LR: 0.001000, Loss: 0.0841680\n",
      "Epoch: 209, LR: 0.001000, Loss: 0.1321184\n",
      "Epoch: 210, LR: 0.001000, Loss: 0.2229384\n",
      "Epoch: 211, LR: 0.001000, Loss: 0.4295563\n",
      "Epoch: 212, LR: 0.001000, Loss: 1.2323267\n",
      "Epoch: 213, LR: 0.001000, Loss: 3.1730287\n",
      "Epoch: 214, LR: 0.001000, Loss: 10.5905066\n",
      "Epoch: 215, LR: 0.001000, Loss: 28.6948471\n",
      "Epoch: 216, LR: 0.001000, Loss: 84.5634689\n",
      "Epoch: 217, LR: 0.001000, Loss: 102.2380295\n",
      "Epoch: 218, LR: 0.001000, Loss: 56.0150757\n",
      "Epoch: 219, LR: 0.001000, Loss: 11.0467348\n",
      "Epoch: 220, LR: 0.001000, Loss: 55.7916183\n",
      "Epoch: 221, LR: 0.001000, Loss: 39.9825897\n",
      "Epoch: 222, LR: 0.001000, Loss: 6.7121091\n",
      "Epoch: 223, LR: 0.001000, Loss: 40.2218895\n",
      "Epoch: 224, LR: 0.001000, Loss: 24.9719391\n",
      "Epoch: 225, LR: 0.001000, Loss: 8.1962919\n",
      "Epoch: 226, LR: 0.001000, Loss: 31.8724747\n",
      "Epoch: 227, LR: 0.001000, Loss: 6.0818944\n",
      "Epoch: 228, LR: 0.001000, Loss: 16.6384525\n",
      "Epoch: 229, LR: 0.001000, Loss: 15.8572025\n",
      "Epoch: 230, LR: 0.001000, Loss: 4.3248868\n",
      "Epoch: 231, LR: 0.001000, Loss: 17.6740017\n",
      "Epoch: 232, LR: 0.001000, Loss: 2.5684462\n",
      "Epoch: 233, LR: 0.001000, Loss: 12.1626501\n",
      "Epoch: 234, LR: 0.001000, Loss: 9.1743078\n",
      "Epoch: 235, LR: 0.001000, Loss: 2.0100420\n",
      "Epoch: 236, LR: 0.001000, Loss: 11.8064461\n",
      "Epoch: 237, LR: 0.001000, Loss: 3.1467974\n",
      "Epoch: 238, LR: 0.001000, Loss: 5.8786111\n",
      "Epoch: 239, LR: 0.001000, Loss: 6.6658149\n",
      "Epoch: 240, LR: 0.001000, Loss: 1.4405051\n",
      "Epoch: 241, LR: 0.001000, Loss: 6.7313347\n",
      "Epoch: 242, LR: 0.001000, Loss: 1.5902680\n",
      "Epoch: 243, LR: 0.001000, Loss: 3.5095897\n",
      "Epoch: 244, LR: 0.001000, Loss: 3.4386406\n",
      "Epoch: 245, LR: 0.001000, Loss: 0.7377024\n",
      "Epoch: 246, LR: 0.001000, Loss: 3.7950330\n",
      "Epoch: 247, LR: 0.001000, Loss: 0.8922849\n",
      "Epoch: 248, LR: 0.001000, Loss: 2.5709076\n",
      "Epoch: 249, LR: 0.001000, Loss: 1.4545046\n",
      "Epoch: 250, LR: 0.001000, Loss: 1.1890213\n",
      "Epoch: 251, LR: 0.001000, Loss: 1.7958947\n",
      "Epoch: 252, LR: 0.001000, Loss: 0.5406993\n",
      "Epoch: 253, LR: 0.001000, Loss: 1.7664510\n",
      "Epoch: 254, LR: 0.001000, Loss: 0.4160322\n",
      "Epoch: 255, LR: 0.001000, Loss: 1.3977203\n",
      "Epoch: 256, LR: 0.001000, Loss: 0.5463727\n",
      "Epoch: 257, LR: 0.001000, Loss: 0.9007608\n",
      "Epoch: 258, LR: 0.001000, Loss: 0.7670726\n",
      "Epoch: 259, LR: 0.001000, Loss: 0.4933223\n",
      "Epoch: 260, LR: 0.001000, Loss: 0.8629586\n",
      "Epoch: 261, LR: 0.001000, Loss: 0.2551049\n",
      "Epoch: 262, LR: 0.001000, Loss: 0.7597333\n",
      "Epoch: 263, LR: 0.001000, Loss: 0.2047759\n",
      "Epoch: 264, LR: 0.001000, Loss: 0.5417836\n",
      "Epoch: 265, LR: 0.001000, Loss: 0.3179124\n",
      "Epoch: 266, LR: 0.001000, Loss: 0.3404718\n",
      "Epoch: 267, LR: 0.001000, Loss: 0.3896458\n",
      "Epoch: 268, LR: 0.001000, Loss: 0.1687152\n",
      "Epoch: 269, LR: 0.001000, Loss: 0.3768555\n",
      "Epoch: 270, LR: 0.001000, Loss: 0.1091424\n",
      "Epoch: 271, LR: 0.001000, Loss: 0.3061750\n",
      "Epoch: 272, LR: 0.001000, Loss: 0.1320367\n",
      "Epoch: 273, LR: 0.001000, Loss: 0.2000655\n",
      "Epoch: 274, LR: 0.001000, Loss: 0.1718737\n",
      "Epoch: 275, LR: 0.001000, Loss: 0.1108070\n",
      "Epoch: 276, LR: 0.001000, Loss: 0.1966116\n",
      "Epoch: 277, LR: 0.001000, Loss: 0.0723018\n",
      "Epoch: 278, LR: 0.001000, Loss: 0.1686447\n",
      "Epoch: 279, LR: 0.001000, Loss: 0.0702512\n",
      "Epoch: 280, LR: 0.001000, Loss: 0.1130552\n",
      "Epoch: 281, LR: 0.001000, Loss: 0.0937389\n",
      "Epoch: 282, LR: 0.001000, Loss: 0.0646830\n",
      "Epoch: 283, LR: 0.001000, Loss: 0.1090276\n",
      "Epoch: 284, LR: 0.001000, Loss: 0.0458721\n",
      "Epoch: 285, LR: 0.001000, Loss: 0.0919922\n",
      "Epoch: 286, LR: 0.001000, Loss: 0.0505375\n",
      "Epoch: 287, LR: 0.001000, Loss: 0.0603853\n",
      "Epoch: 288, LR: 0.001000, Loss: 0.0633775\n",
      "Epoch: 289, LR: 0.001000, Loss: 0.0380446\n",
      "Epoch: 290, LR: 0.001000, Loss: 0.0641902\n",
      "Epoch: 291, LR: 0.001000, Loss: 0.0318354\n",
      "Epoch: 292, LR: 0.001000, Loss: 0.0504003\n",
      "Epoch: 293, LR: 0.001000, Loss: 0.0382797\n",
      "Epoch: 294, LR: 0.001000, Loss: 0.0357816\n",
      "Epoch: 295, LR: 0.001000, Loss: 0.0435767\n",
      "Epoch: 296, LR: 0.001000, Loss: 0.0260444\n",
      "Epoch: 297, LR: 0.001000, Loss: 0.0392092\n",
      "Epoch: 298, LR: 0.001000, Loss: 0.0255718\n",
      "Epoch: 299, LR: 0.001000, Loss: 0.0301239\n",
      "Epoch: 300, LR: 0.001000, Loss: 0.0298230\n",
      "Epoch: 301, LR: 0.001000, Loss: 0.0227535\n",
      "Epoch: 302, LR: 0.001000, Loss: 0.0298853\n",
      "Epoch: 303, LR: 0.001000, Loss: 0.0206962\n",
      "Epoch: 304, LR: 0.001000, Loss: 0.0255277\n",
      "Epoch: 305, LR: 0.001000, Loss: 0.0224838\n",
      "Epoch: 306, LR: 0.001000, Loss: 0.0198343\n",
      "Epoch: 307, LR: 0.001000, Loss: 0.0229673\n",
      "Epoch: 308, LR: 0.001000, Loss: 0.0172041\n",
      "Epoch: 309, LR: 0.001000, Loss: 0.0205594\n",
      "Epoch: 310, LR: 0.001000, Loss: 0.0179797\n",
      "Epoch: 311, LR: 0.001000, Loss: 0.0171883\n",
      "Epoch: 312, LR: 0.001000, Loss: 0.0185239\n",
      "Epoch: 313, LR: 0.001000, Loss: 0.0149941\n",
      "Epoch: 314, LR: 0.001000, Loss: 0.0168728\n",
      "Epoch: 315, LR: 0.001000, Loss: 0.0148975\n",
      "Epoch: 316, LR: 0.001000, Loss: 0.0144128\n",
      "Epoch: 317, LR: 0.001000, Loss: 0.0151939\n",
      "Epoch: 318, LR: 0.001000, Loss: 0.0130748\n",
      "Epoch: 319, LR: 0.001000, Loss: 0.0141264\n",
      "Epoch: 320, LR: 0.001000, Loss: 0.0130129\n",
      "Epoch: 321, LR: 0.001000, Loss: 0.0125562\n",
      "Epoch: 322, LR: 0.001000, Loss: 0.0130099\n",
      "Epoch: 323, LR: 0.001000, Loss: 0.0116396\n",
      "Epoch: 324, LR: 0.001000, Loss: 0.0121226\n",
      "Epoch: 325, LR: 0.001000, Loss: 0.0114932\n",
      "Epoch: 326, LR: 0.001000, Loss: 0.0110163\n",
      "Epoch: 327, LR: 0.001000, Loss: 0.0113546\n",
      "Epoch: 328, LR: 0.001000, Loss: 0.0104802\n",
      "Epoch: 329, LR: 0.001000, Loss: 0.0106084\n",
      "Epoch: 330, LR: 0.001000, Loss: 0.0103219\n",
      "Epoch: 331, LR: 0.001000, Loss: 0.0098384\n",
      "Epoch: 332, LR: 0.001000, Loss: 0.0100248\n",
      "Epoch: 333, LR: 0.001000, Loss: 0.0094845\n",
      "Epoch: 334, LR: 0.001000, Loss: 0.0094016\n",
      "Epoch: 335, LR: 0.001000, Loss: 0.0092976\n",
      "Epoch: 336, LR: 0.001000, Loss: 0.0088732\n",
      "Epoch: 337, LR: 0.001000, Loss: 0.0089376\n",
      "Epoch: 338, LR: 0.001000, Loss: 0.0086368\n",
      "Epoch: 339, LR: 0.001000, Loss: 0.0084294\n",
      "Epoch: 340, LR: 0.001000, Loss: 0.0083949\n",
      "Epoch: 341, LR: 0.001000, Loss: 0.0080645\n",
      "Epoch: 342, LR: 0.001000, Loss: 0.0080000\n",
      "Epoch: 343, LR: 0.001000, Loss: 0.0078480\n",
      "Epoch: 344, LR: 0.001000, Loss: 0.0076107\n",
      "Epoch: 345, LR: 0.001000, Loss: 0.0075644\n",
      "Epoch: 346, LR: 0.001000, Loss: 0.0073469\n",
      "Epoch: 347, LR: 0.001000, Loss: 0.0072012\n",
      "Epoch: 348, LR: 0.001000, Loss: 0.0071132\n",
      "Epoch: 349, LR: 0.001000, Loss: 0.0068997\n",
      "Epoch: 350, LR: 0.001000, Loss: 0.0068056\n",
      "Epoch: 351, LR: 0.001000, Loss: 0.0066707\n",
      "Epoch: 352, LR: 0.001000, Loss: 0.0064989\n",
      "Epoch: 353, LR: 0.001000, Loss: 0.0064195\n",
      "Epoch: 354, LR: 0.001000, Loss: 0.0062661\n",
      "Epoch: 355, LR: 0.001000, Loss: 0.0061325\n",
      "Epoch: 356, LR: 0.001000, Loss: 0.0060379\n",
      "Epoch: 357, LR: 0.001000, Loss: 0.0058873\n",
      "Epoch: 358, LR: 0.001000, Loss: 0.0057814\n",
      "Epoch: 359, LR: 0.001000, Loss: 0.0056761\n",
      "Epoch: 360, LR: 0.001000, Loss: 0.0055411\n",
      "Epoch: 361, LR: 0.001000, Loss: 0.0054465\n",
      "Epoch: 362, LR: 0.001000, Loss: 0.0053361\n",
      "Epoch: 363, LR: 0.001000, Loss: 0.0052168\n",
      "Epoch: 364, LR: 0.001000, Loss: 0.0051273\n",
      "Epoch: 365, LR: 0.001000, Loss: 0.0050150\n",
      "Epoch: 366, LR: 0.001000, Loss: 0.0049114\n",
      "Epoch: 367, LR: 0.001000, Loss: 0.0048221\n",
      "Epoch: 368, LR: 0.001000, Loss: 0.0047153\n",
      "Epoch: 369, LR: 0.001000, Loss: 0.0046228\n",
      "Epoch: 370, LR: 0.001000, Loss: 0.0045342\n",
      "Epoch: 371, LR: 0.001000, Loss: 0.0044346\n",
      "Epoch: 372, LR: 0.001000, Loss: 0.0043484\n",
      "Epoch: 373, LR: 0.001000, Loss: 0.0042627\n",
      "Epoch: 374, LR: 0.001000, Loss: 0.0041696\n",
      "Epoch: 375, LR: 0.001000, Loss: 0.0040885\n",
      "Epoch: 376, LR: 0.001000, Loss: 0.0040046\n",
      "Epoch: 377, LR: 0.001000, Loss: 0.0039196\n",
      "Epoch: 378, LR: 0.001000, Loss: 0.0038427\n",
      "Epoch: 379, LR: 0.001000, Loss: 0.0037625\n",
      "Epoch: 380, LR: 0.001000, Loss: 0.0036836\n",
      "Epoch: 381, LR: 0.001000, Loss: 0.0036095\n",
      "Epoch: 382, LR: 0.001000, Loss: 0.0035334\n",
      "Epoch: 383, LR: 0.001000, Loss: 0.0034594\n",
      "Epoch: 384, LR: 0.001000, Loss: 0.0033894\n",
      "Epoch: 385, LR: 0.001000, Loss: 0.0033174\n",
      "Epoch: 386, LR: 0.001000, Loss: 0.0032482\n",
      "Epoch: 387, LR: 0.001000, Loss: 0.0031813\n",
      "Epoch: 388, LR: 0.001000, Loss: 0.0031135\n",
      "Epoch: 389, LR: 0.001000, Loss: 0.0030476\n",
      "Epoch: 390, LR: 0.001000, Loss: 0.0029843\n",
      "Epoch: 391, LR: 0.001000, Loss: 0.0029203\n",
      "Epoch: 392, LR: 0.001000, Loss: 0.0028583\n",
      "Epoch: 393, LR: 0.001000, Loss: 0.0027989\n",
      "Epoch: 394, LR: 0.001000, Loss: 0.0027388\n",
      "Epoch: 395, LR: 0.001000, Loss: 0.0026806\n",
      "Epoch: 396, LR: 0.001000, Loss: 0.0026232\n",
      "Epoch: 397, LR: 0.001000, Loss: 0.0025663\n",
      "Epoch: 398, LR: 0.001000, Loss: 0.0025115\n",
      "Epoch: 399, LR: 0.001000, Loss: 0.0024581\n",
      "Epoch: 400, LR: 0.001000, Loss: 0.0024040\n",
      "Epoch: 401, LR: 0.001000, Loss: 0.0023521\n",
      "Epoch: 402, LR: 0.001000, Loss: 0.0023011\n",
      "Epoch: 403, LR: 0.001000, Loss: 0.0022512\n",
      "Epoch: 404, LR: 0.001000, Loss: 0.0022016\n",
      "Epoch: 405, LR: 0.001000, Loss: 0.0021541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 406, LR: 0.001000, Loss: 0.0021066\n",
      "Epoch: 407, LR: 0.001000, Loss: 0.0020602\n",
      "Epoch: 408, LR: 0.001000, Loss: 0.0020158\n",
      "Epoch: 409, LR: 0.001000, Loss: 0.0019704\n",
      "Epoch: 410, LR: 0.001000, Loss: 0.0019272\n",
      "Epoch: 411, LR: 0.001000, Loss: 0.0018851\n",
      "Epoch: 412, LR: 0.001000, Loss: 0.0018431\n",
      "Epoch: 413, LR: 0.001000, Loss: 0.0018024\n",
      "Epoch: 414, LR: 0.001000, Loss: 0.0017617\n",
      "Epoch: 415, LR: 0.001000, Loss: 0.0017228\n",
      "Epoch: 416, LR: 0.001000, Loss: 0.0016846\n",
      "Epoch: 417, LR: 0.001000, Loss: 0.0016468\n",
      "Epoch: 418, LR: 0.001000, Loss: 0.0016101\n",
      "Epoch: 419, LR: 0.001000, Loss: 0.0015735\n",
      "Epoch: 420, LR: 0.001000, Loss: 0.0015387\n",
      "Epoch: 421, LR: 0.001000, Loss: 0.0015041\n",
      "Epoch: 422, LR: 0.001000, Loss: 0.0014697\n",
      "Epoch: 423, LR: 0.001000, Loss: 0.0014366\n",
      "Epoch: 424, LR: 0.001000, Loss: 0.0014043\n",
      "Epoch: 425, LR: 0.001000, Loss: 0.0013723\n",
      "Epoch: 426, LR: 0.001000, Loss: 0.0013413\n",
      "Epoch: 427, LR: 0.001000, Loss: 0.0013102\n",
      "Epoch: 428, LR: 0.001000, Loss: 0.0012807\n",
      "Epoch: 429, LR: 0.001000, Loss: 0.0012515\n",
      "Epoch: 430, LR: 0.001000, Loss: 0.0012231\n",
      "Epoch: 431, LR: 0.001000, Loss: 0.0011946\n",
      "Epoch: 432, LR: 0.001000, Loss: 0.0011675\n",
      "Epoch: 433, LR: 0.001000, Loss: 0.0011405\n",
      "Epoch: 434, LR: 0.001000, Loss: 0.0011142\n",
      "Epoch: 435, LR: 0.001000, Loss: 0.0010884\n",
      "Epoch: 436, LR: 0.001000, Loss: 0.0010632\n",
      "Epoch: 437, LR: 0.001000, Loss: 0.0010386\n",
      "Epoch: 438, LR: 0.001000, Loss: 0.0010144\n",
      "Epoch: 439, LR: 0.001000, Loss: 0.0009915\n",
      "Epoch: 440, LR: 0.001000, Loss: 0.0009681\n",
      "Epoch: 441, LR: 0.001000, Loss: 0.0009455\n",
      "Epoch: 442, LR: 0.001000, Loss: 0.0009234\n",
      "Epoch: 443, LR: 0.001000, Loss: 0.0009018\n",
      "Epoch: 444, LR: 0.001000, Loss: 0.0008806\n",
      "Epoch: 445, LR: 0.001000, Loss: 0.0008600\n",
      "Epoch: 446, LR: 0.001000, Loss: 0.0008401\n",
      "Epoch: 447, LR: 0.001000, Loss: 0.0008201\n",
      "Epoch: 448, LR: 0.001000, Loss: 0.0008010\n",
      "Epoch: 449, LR: 0.001000, Loss: 0.0007821\n",
      "Epoch: 450, LR: 0.001000, Loss: 0.0007636\n",
      "Epoch: 451, LR: 0.001000, Loss: 0.0007453\n",
      "Epoch: 452, LR: 0.001000, Loss: 0.0007279\n",
      "Epoch: 453, LR: 0.001000, Loss: 0.0007107\n",
      "Epoch: 454, LR: 0.001000, Loss: 0.0006936\n",
      "Epoch: 455, LR: 0.001000, Loss: 0.0006774\n",
      "Epoch: 456, LR: 0.001000, Loss: 0.0006609\n",
      "Epoch: 457, LR: 0.001000, Loss: 0.0006451\n",
      "Epoch: 458, LR: 0.001000, Loss: 0.0006299\n",
      "Epoch: 459, LR: 0.001000, Loss: 0.0006148\n",
      "Epoch: 460, LR: 0.001000, Loss: 0.0006000\n",
      "Epoch: 461, LR: 0.001000, Loss: 0.0005856\n",
      "Epoch: 462, LR: 0.001000, Loss: 0.0005717\n",
      "Epoch: 463, LR: 0.001000, Loss: 0.0005580\n",
      "Epoch: 464, LR: 0.001000, Loss: 0.0005445\n",
      "Epoch: 465, LR: 0.001000, Loss: 0.0005312\n",
      "Epoch: 466, LR: 0.001000, Loss: 0.0005186\n",
      "Epoch: 467, LR: 0.001000, Loss: 0.0005060\n",
      "Epoch: 468, LR: 0.001000, Loss: 0.0004939\n",
      "Epoch: 469, LR: 0.001000, Loss: 0.0004820\n",
      "Epoch: 470, LR: 0.001000, Loss: 0.0004701\n",
      "Epoch: 471, LR: 0.001000, Loss: 0.0004587\n",
      "Epoch: 472, LR: 0.001000, Loss: 0.0004477\n",
      "Epoch: 473, LR: 0.001000, Loss: 0.0004366\n",
      "Epoch: 474, LR: 0.001000, Loss: 0.0004260\n",
      "Epoch: 475, LR: 0.001000, Loss: 0.0004155\n",
      "Epoch: 476, LR: 0.001000, Loss: 0.0004057\n",
      "Epoch: 477, LR: 0.001000, Loss: 0.0003954\n",
      "Epoch: 478, LR: 0.001000, Loss: 0.0003858\n",
      "Epoch: 479, LR: 0.001000, Loss: 0.0003763\n",
      "Epoch: 480, LR: 0.001000, Loss: 0.0003673\n",
      "Epoch: 481, LR: 0.001000, Loss: 0.0003584\n",
      "Epoch: 482, LR: 0.001000, Loss: 0.0003492\n",
      "Epoch: 483, LR: 0.001000, Loss: 0.0003407\n",
      "Epoch: 484, LR: 0.001000, Loss: 0.0003322\n",
      "Epoch: 485, LR: 0.001000, Loss: 0.0003241\n",
      "Epoch: 486, LR: 0.001000, Loss: 0.0003161\n",
      "Epoch: 487, LR: 0.001000, Loss: 0.0003083\n",
      "Epoch: 488, LR: 0.001000, Loss: 0.0003005\n",
      "Epoch: 489, LR: 0.001000, Loss: 0.0002932\n",
      "Epoch: 490, LR: 0.001000, Loss: 0.0002857\n",
      "Epoch: 491, LR: 0.001000, Loss: 0.0002787\n",
      "Epoch: 492, LR: 0.001000, Loss: 0.0002719\n",
      "Epoch: 493, LR: 0.001000, Loss: 0.0002650\n",
      "Epoch: 494, LR: 0.001000, Loss: 0.0002583\n",
      "Epoch: 495, LR: 0.001000, Loss: 0.0002519\n",
      "Epoch: 496, LR: 0.001000, Loss: 0.0002455\n",
      "Epoch: 497, LR: 0.001000, Loss: 0.0002392\n",
      "Epoch: 498, LR: 0.001000, Loss: 0.0002335\n",
      "Epoch: 499, LR: 0.001000, Loss: 0.0002276\n",
      "Epoch: 500, LR: 0.001000, Loss: 0.0002217\n",
      "Epoch: 501, LR: 0.001000, Loss: 0.0002162\n",
      "Epoch: 502, LR: 0.001000, Loss: 0.0002108\n",
      "Epoch: 503, LR: 0.001000, Loss: 0.0002055\n",
      "Epoch: 504, LR: 0.001000, Loss: 0.0002003\n",
      "Epoch: 505, LR: 0.001000, Loss: 0.0001951\n",
      "Epoch: 506, LR: 0.001000, Loss: 0.0001902\n",
      "Epoch: 507, LR: 0.001000, Loss: 0.0001854\n",
      "Epoch: 508, LR: 0.001000, Loss: 0.0001806\n",
      "Epoch: 509, LR: 0.001000, Loss: 0.0001761\n",
      "Epoch: 510, LR: 0.001000, Loss: 0.0001715\n",
      "Epoch: 511, LR: 0.001000, Loss: 0.0001672\n",
      "Epoch: 512, LR: 0.001000, Loss: 0.0001627\n",
      "Epoch: 513, LR: 0.001000, Loss: 0.0001588\n",
      "Epoch: 514, LR: 0.001000, Loss: 0.0001546\n",
      "Epoch: 515, LR: 0.001000, Loss: 0.0001506\n",
      "Epoch: 516, LR: 0.001000, Loss: 0.0001468\n",
      "Epoch: 517, LR: 0.001000, Loss: 0.0001429\n",
      "Epoch: 518, LR: 0.001000, Loss: 0.0001393\n",
      "Epoch: 519, LR: 0.001000, Loss: 0.0001358\n",
      "Epoch: 520, LR: 0.001000, Loss: 0.0001322\n",
      "Epoch: 521, LR: 0.001000, Loss: 0.0001288\n",
      "Epoch: 522, LR: 0.001000, Loss: 0.0001255\n",
      "Epoch: 523, LR: 0.001000, Loss: 0.0001222\n",
      "Epoch: 524, LR: 0.001000, Loss: 0.0001191\n",
      "Epoch: 525, LR: 0.001000, Loss: 0.0001159\n",
      "Epoch: 526, LR: 0.001000, Loss: 0.0001130\n",
      "Epoch: 527, LR: 0.001000, Loss: 0.0001100\n",
      "Epoch: 528, LR: 0.001000, Loss: 0.0001071\n",
      "Epoch: 529, LR: 0.001000, Loss: 0.0001043\n",
      "Epoch: 530, LR: 0.001000, Loss: 0.0001017\n",
      "Epoch: 531, LR: 0.001000, Loss: 0.0000989\n",
      "Epoch: 532, LR: 0.001000, Loss: 0.0000964\n",
      "Epoch: 533, LR: 0.001000, Loss: 0.0000938\n",
      "Epoch: 534, LR: 0.001000, Loss: 0.0000913\n",
      "Epoch: 535, LR: 0.001000, Loss: 0.0000890\n",
      "Epoch: 536, LR: 0.001000, Loss: 0.0000867\n",
      "Epoch: 537, LR: 0.001000, Loss: 0.0000843\n",
      "Epoch: 538, LR: 0.001000, Loss: 0.0000820\n",
      "Epoch: 539, LR: 0.001000, Loss: 0.0000799\n",
      "Epoch: 540, LR: 0.001000, Loss: 0.0000778\n",
      "Epoch: 541, LR: 0.001000, Loss: 0.0000759\n",
      "Epoch: 542, LR: 0.001000, Loss: 0.0000737\n",
      "Epoch: 543, LR: 0.001000, Loss: 0.0000718\n",
      "Epoch: 544, LR: 0.001000, Loss: 0.0000700\n",
      "Epoch: 545, LR: 0.001000, Loss: 0.0000681\n",
      "Epoch: 546, LR: 0.001000, Loss: 0.0000662\n",
      "Epoch: 547, LR: 0.001000, Loss: 0.0000644\n",
      "Epoch: 548, LR: 0.001000, Loss: 0.0000627\n",
      "Epoch: 549, LR: 0.001000, Loss: 0.0000610\n",
      "Epoch: 550, LR: 0.001000, Loss: 0.0000594\n",
      "Epoch: 551, LR: 0.001000, Loss: 0.0000578\n",
      "Epoch: 552, LR: 0.001000, Loss: 0.0000563\n",
      "Epoch: 553, LR: 0.001000, Loss: 0.0000547\n",
      "Epoch: 554, LR: 0.001000, Loss: 0.0000532\n",
      "Epoch: 555, LR: 0.001000, Loss: 0.0000519\n",
      "Epoch: 556, LR: 0.001000, Loss: 0.0000504\n",
      "Epoch: 557, LR: 0.001000, Loss: 0.0000491\n",
      "Epoch: 558, LR: 0.001000, Loss: 0.0000477\n",
      "Epoch: 559, LR: 0.001000, Loss: 0.0000464\n",
      "Epoch: 560, LR: 0.001000, Loss: 0.0000452\n",
      "Epoch: 561, LR: 0.001000, Loss: 0.0000439\n",
      "Epoch: 562, LR: 0.001000, Loss: 0.0000427\n",
      "Epoch: 563, LR: 0.001000, Loss: 0.0000415\n",
      "Epoch: 564, LR: 0.001000, Loss: 0.0000405\n",
      "Epoch: 565, LR: 0.001000, Loss: 0.0000394\n",
      "Epoch: 566, LR: 0.001000, Loss: 0.0000382\n",
      "Epoch: 567, LR: 0.001000, Loss: 0.0000372\n",
      "Epoch: 568, LR: 0.001000, Loss: 0.0000362\n",
      "Epoch: 569, LR: 0.001000, Loss: 0.0000352\n",
      "Epoch: 570, LR: 0.001000, Loss: 0.0000342\n",
      "Epoch: 571, LR: 0.001000, Loss: 0.0000333\n",
      "Epoch: 572, LR: 0.001000, Loss: 0.0000323\n",
      "Epoch: 573, LR: 0.001000, Loss: 0.0000315\n",
      "Epoch: 574, LR: 0.001000, Loss: 0.0000306\n",
      "Epoch: 575, LR: 0.001000, Loss: 0.0000297\n",
      "Epoch: 576, LR: 0.001000, Loss: 0.0000289\n",
      "Epoch: 577, LR: 0.001000, Loss: 0.0000281\n",
      "Epoch: 578, LR: 0.001000, Loss: 0.0000273\n",
      "Epoch: 579, LR: 0.001000, Loss: 0.0000266\n",
      "Epoch: 580, LR: 0.001000, Loss: 0.0000259\n",
      "Epoch: 581, LR: 0.001000, Loss: 0.0000252\n",
      "Epoch: 582, LR: 0.001000, Loss: 0.0000243\n",
      "Epoch: 583, LR: 0.001000, Loss: 0.0000237\n",
      "Epoch: 584, LR: 0.001000, Loss: 0.0000231\n",
      "Epoch: 585, LR: 0.001000, Loss: 0.0000225\n",
      "Epoch: 586, LR: 0.001000, Loss: 0.0000218\n",
      "Epoch: 587, LR: 0.001000, Loss: 0.0000212\n",
      "Epoch: 588, LR: 0.001000, Loss: 0.0000206\n",
      "Epoch: 589, LR: 0.001000, Loss: 0.0000200\n",
      "Epoch: 590, LR: 0.001000, Loss: 0.0000195\n",
      "Epoch: 591, LR: 0.001000, Loss: 0.0000189\n",
      "Epoch: 592, LR: 0.001000, Loss: 0.0000184\n",
      "Epoch: 593, LR: 0.001000, Loss: 0.0000179\n",
      "Epoch: 594, LR: 0.001000, Loss: 0.0000173\n",
      "Epoch: 595, LR: 0.001000, Loss: 0.0000169\n",
      "Epoch: 596, LR: 0.001000, Loss: 0.0000164\n",
      "Epoch: 597, LR: 0.001000, Loss: 0.0000159\n",
      "Epoch: 598, LR: 0.001000, Loss: 0.0000155\n",
      "Epoch: 599, LR: 0.001000, Loss: 0.0000150\n",
      "Epoch: 600, LR: 0.001000, Loss: 0.0000146\n",
      "Epoch: 601, LR: 0.001000, Loss: 0.0000142\n",
      "Epoch: 602, LR: 0.001000, Loss: 0.0000138\n",
      "Epoch: 603, LR: 0.001000, Loss: 0.0000134\n",
      "Epoch: 604, LR: 0.001000, Loss: 0.0000130\n",
      "Epoch: 605, LR: 0.001000, Loss: 0.0000127\n",
      "Epoch: 606, LR: 0.001000, Loss: 0.0000123\n",
      "Epoch: 607, LR: 0.001000, Loss: 0.0000119\n",
      "Epoch: 608, LR: 0.001000, Loss: 0.0000116\n",
      "Epoch: 609, LR: 0.001000, Loss: 0.0000113\n",
      "Epoch: 610, LR: 0.001000, Loss: 0.0000109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 611, LR: 0.001000, Loss: 0.0000106\n",
      "Epoch: 612, LR: 0.001000, Loss: 0.0000103\n",
      "Epoch: 613, LR: 0.001000, Loss: 0.0000101\n",
      "Epoch: 614, LR: 0.001000, Loss: 0.0000097\n",
      "Epoch: 615, LR: 0.001000, Loss: 0.0000094\n",
      "Epoch: 616, LR: 0.001000, Loss: 0.0000091\n",
      "Epoch: 617, LR: 0.001000, Loss: 0.0000089\n",
      "Epoch: 618, LR: 0.001000, Loss: 0.0000086\n",
      "Epoch: 619, LR: 0.001000, Loss: 0.0000084\n",
      "Epoch: 620, LR: 0.001000, Loss: 0.0000081\n",
      "Epoch: 621, LR: 0.001000, Loss: 0.0000079\n",
      "Epoch: 622, LR: 0.001000, Loss: 0.0000077\n",
      "Epoch: 623, LR: 0.001000, Loss: 0.0000075\n",
      "Epoch: 624, LR: 0.001000, Loss: 0.0000073\n",
      "Epoch: 625, LR: 0.001000, Loss: 0.0000070\n",
      "Epoch: 626, LR: 0.001000, Loss: 0.0000068\n",
      "Epoch: 627, LR: 0.001000, Loss: 0.0000066\n",
      "Epoch: 628, LR: 0.001000, Loss: 0.0000065\n",
      "Epoch: 629, LR: 0.001000, Loss: 0.0000063\n",
      "Epoch: 630, LR: 0.001000, Loss: 0.0000061\n",
      "Epoch: 631, LR: 0.001000, Loss: 0.0000059\n",
      "Epoch: 632, LR: 0.001000, Loss: 0.0000057\n",
      "Epoch: 633, LR: 0.001000, Loss: 0.0000055\n",
      "Epoch: 634, LR: 0.001000, Loss: 0.0000054\n",
      "Epoch: 635, LR: 0.001000, Loss: 0.0000052\n",
      "Epoch: 636, LR: 0.001000, Loss: 0.0000051\n",
      "Epoch: 637, LR: 0.001000, Loss: 0.0000049\n",
      "Epoch: 638, LR: 0.001000, Loss: 0.0000048\n",
      "Epoch: 639, LR: 0.001000, Loss: 0.0000047\n",
      "Epoch: 640, LR: 0.001000, Loss: 0.0000045\n",
      "Epoch: 641, LR: 0.001000, Loss: 0.0000043\n",
      "Epoch: 642, LR: 0.001000, Loss: 0.0000042\n",
      "Epoch: 643, LR: 0.001000, Loss: 0.0000041\n",
      "Epoch: 644, LR: 0.001000, Loss: 0.0000040\n",
      "Epoch: 645, LR: 0.001000, Loss: 0.0000039\n",
      "Epoch: 646, LR: 0.001000, Loss: 0.0000037\n",
      "Epoch: 647, LR: 0.001000, Loss: 0.0000036\n",
      "Epoch: 648, LR: 0.001000, Loss: 0.0000035\n",
      "Epoch: 649, LR: 0.001000, Loss: 0.0000034\n",
      "Epoch: 650, LR: 0.001000, Loss: 0.0000033\n",
      "Epoch: 651, LR: 0.001000, Loss: 0.0000032\n",
      "Epoch: 652, LR: 0.001000, Loss: 0.0000031\n",
      "Epoch: 653, LR: 0.001000, Loss: 0.0000030\n",
      "Epoch: 654, LR: 0.001000, Loss: 0.0000029\n",
      "Epoch: 655, LR: 0.001000, Loss: 0.0000029\n",
      "Epoch: 656, LR: 0.001000, Loss: 0.0000028\n",
      "Epoch: 657, LR: 0.001000, Loss: 0.0000027\n",
      "Epoch: 658, LR: 0.001000, Loss: 0.0000026\n",
      "Epoch: 659, LR: 0.001000, Loss: 0.0000025\n",
      "Epoch: 660, LR: 0.001000, Loss: 0.0000024\n",
      "Epoch: 661, LR: 0.001000, Loss: 0.0000023\n",
      "Epoch: 662, LR: 0.001000, Loss: 0.0000023\n",
      "Epoch: 663, LR: 0.001000, Loss: 0.0000022\n",
      "Epoch: 664, LR: 0.001000, Loss: 0.0000022\n",
      "Epoch: 665, LR: 0.001000, Loss: 0.0000021\n",
      "Epoch: 666, LR: 0.001000, Loss: 0.0000020\n",
      "Epoch: 667, LR: 0.001000, Loss: 0.0000020\n",
      "Epoch: 668, LR: 0.001000, Loss: 0.0000019\n",
      "Epoch: 669, LR: 0.001000, Loss: 0.0000019\n",
      "Epoch: 670, LR: 0.001000, Loss: 0.0000018\n",
      "Epoch: 671, LR: 0.001000, Loss: 0.0000018\n",
      "Epoch: 672, LR: 0.001000, Loss: 0.0000017\n",
      "Epoch: 673, LR: 0.001000, Loss: 0.0000016\n",
      "Epoch: 674, LR: 0.001000, Loss: 0.0000016\n",
      "Epoch: 675, LR: 0.001000, Loss: 0.0000015\n",
      "Epoch: 676, LR: 0.001000, Loss: 0.0000015\n",
      "Epoch: 677, LR: 0.001000, Loss: 0.0000015\n",
      "Epoch: 678, LR: 0.001000, Loss: 0.0000014\n",
      "Epoch: 679, LR: 0.001000, Loss: 0.0000014\n",
      "Epoch: 680, LR: 0.001000, Loss: 0.0000013\n",
      "Epoch: 681, LR: 0.001000, Loss: 0.0000013\n",
      "Epoch: 682, LR: 0.001000, Loss: 0.0000012\n",
      "Epoch: 683, LR: 0.001000, Loss: 0.0000012\n",
      "Epoch: 684, LR: 0.001000, Loss: 0.0000012\n",
      "Epoch: 685, LR: 0.001000, Loss: 0.0000011\n",
      "Epoch: 686, LR: 0.001000, Loss: 0.0000011\n",
      "Epoch: 687, LR: 0.001000, Loss: 0.0000011\n",
      "Epoch: 688, LR: 0.001000, Loss: 0.0000010\n",
      "Epoch: 689, LR: 0.001000, Loss: 0.0000010\n",
      "Epoch: 690, LR: 0.001000, Loss: 0.0000010\n",
      "Epoch: 691, LR: 0.001000, Loss: 0.0000009\n",
      "Epoch: 692, LR: 0.001000, Loss: 0.0000009\n",
      "Epoch: 693, LR: 0.001000, Loss: 0.0000009\n",
      "Epoch: 694, LR: 0.001000, Loss: 0.0000009\n",
      "Epoch: 695, LR: 0.001000, Loss: 0.0000008\n",
      "Epoch: 696, LR: 0.001000, Loss: 0.0000008\n",
      "Epoch: 697, LR: 0.001000, Loss: 0.0000008\n",
      "Epoch: 698, LR: 0.001000, Loss: 0.0000008\n",
      "Epoch: 699, LR: 0.001000, Loss: 0.0000007\n",
      "Epoch: 700, LR: 0.001000, Loss: 0.0000007\n",
      "Epoch: 701, LR: 0.001000, Loss: 0.0000007\n",
      "Epoch: 702, LR: 0.001000, Loss: 0.0000007\n",
      "Epoch: 703, LR: 0.001000, Loss: 0.0000007\n",
      "Epoch: 704, LR: 0.001000, Loss: 0.0000006\n",
      "Epoch: 705, LR: 0.001000, Loss: 0.0000006\n",
      "Epoch: 706, LR: 0.001000, Loss: 0.0000006\n",
      "Epoch: 707, LR: 0.001000, Loss: 0.0000006\n",
      "Epoch: 708, LR: 0.001000, Loss: 0.0000006\n",
      "Epoch: 709, LR: 0.001000, Loss: 0.0000005\n",
      "Epoch: 710, LR: 0.001000, Loss: 0.0000005\n",
      "Epoch: 711, LR: 0.001000, Loss: 0.0000005\n",
      "Epoch: 712, LR: 0.001000, Loss: 0.0000005\n",
      "Epoch: 713, LR: 0.001000, Loss: 0.0000005\n",
      "Epoch: 714, LR: 0.001000, Loss: 0.0000005\n",
      "Epoch: 715, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 716, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 717, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 718, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 719, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 720, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 721, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 722, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 723, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 724, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 725, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 726, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 727, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 728, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 729, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 730, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 731, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 732, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 733, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 734, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 735, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 736, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 737, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 738, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 739, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 740, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 741, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 742, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 743, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 744, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 745, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 746, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 747, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 748, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 749, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 750, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 751, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 752, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 753, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 754, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 755, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 756, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 757, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 758, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 759, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 760, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 761, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 762, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 763, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 764, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 765, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 766, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 767, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 768, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 769, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 770, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 771, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 772, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 773, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 774, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 775, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 776, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 777, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 778, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 779, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 780, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 781, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 782, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 783, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 784, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 785, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 786, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 787, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 788, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 789, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 790, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 791, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 792, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 793, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 794, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 795, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 796, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 797, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 798, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 799, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 800, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 801, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 802, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 803, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 804, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 805, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 806, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 807, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 808, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 809, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 810, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 811, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 812, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 813, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 814, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 815, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 816, LR: 0.001000, Loss: 0.0000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 817, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 818, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 819, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 820, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 821, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 822, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 823, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 824, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 825, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 826, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 827, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 828, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 829, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 830, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 831, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 832, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 833, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 834, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 835, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 836, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 837, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 838, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 839, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 840, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 841, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 842, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 843, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 844, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 845, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 846, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 847, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 848, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 849, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 850, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 851, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 852, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 853, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 854, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 855, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 856, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 857, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 858, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 859, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 860, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 861, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 862, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 863, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 864, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 865, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 866, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 867, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 868, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 869, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 870, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 871, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 872, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 873, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 874, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 875, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 876, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 877, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 878, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 879, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 880, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 881, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 882, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 883, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 884, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 885, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 886, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 887, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 888, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 889, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 890, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 891, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 892, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 893, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 894, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 895, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 896, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 897, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 898, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 899, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 900, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 901, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 902, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 903, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 904, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 905, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 906, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 907, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 908, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 909, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 910, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 911, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 912, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 913, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 914, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 915, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 916, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 917, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 918, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 919, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 920, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 921, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 922, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 923, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 924, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 925, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 926, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 927, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 928, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 929, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 930, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 931, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 932, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 933, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 934, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 935, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 936, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 937, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 938, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 939, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 940, LR: 0.001000, Loss: 0.0000030\n",
      "Epoch: 941, LR: 0.001000, Loss: 0.0000254\n",
      "Epoch: 942, LR: 0.001000, Loss: 0.0002140\n",
      "Epoch: 943, LR: 0.001000, Loss: 0.0018100\n",
      "Epoch: 944, LR: 0.001000, Loss: 0.0153739\n",
      "Epoch: 945, LR: 0.001000, Loss: 0.1315849\n",
      "Epoch: 946, LR: 0.001000, Loss: 1.1435584\n",
      "Epoch: 947, LR: 0.001000, Loss: 10.0814695\n",
      "Epoch: 948, LR: 0.001000, Loss: 101.2050781\n",
      "Epoch: 949, LR: 0.001000, Loss: 868.4223022\n",
      "Epoch: 950, LR: 0.001000, Loss: 2323.7541504\n",
      "Epoch: 951, LR: 0.001000, Loss: 1259.4149170\n",
      "Epoch: 952, LR: 0.001000, Loss: 889.3533936\n",
      "Epoch: 953, LR: 0.001000, Loss: 1346.7769775\n",
      "Epoch: 954, LR: 0.001000, Loss: 405.1505432\n",
      "Epoch: 955, LR: 0.001000, Loss: 410.0548706\n",
      "Epoch: 956, LR: 0.001000, Loss: 679.2418823\n",
      "Epoch: 957, LR: 0.001000, Loss: 841.9625244\n",
      "Epoch: 958, LR: 0.001000, Loss: 238.0797729\n",
      "Epoch: 959, LR: 0.001000, Loss: 510.5323486\n",
      "Epoch: 960, LR: 0.001000, Loss: 175.3095398\n",
      "Epoch: 961, LR: 0.001000, Loss: 231.8554840\n",
      "Epoch: 962, LR: 0.001000, Loss: 834.5871582\n",
      "Epoch: 963, LR: 0.001000, Loss: 458.6112671\n",
      "Epoch: 964, LR: 0.001000, Loss: 341.4786377\n",
      "Epoch: 965, LR: 0.001000, Loss: 139.7036896\n",
      "Epoch: 966, LR: 0.001000, Loss: 323.4618530\n",
      "Epoch: 967, LR: 0.001000, Loss: 224.5146484\n",
      "Epoch: 968, LR: 0.001000, Loss: 102.3115234\n",
      "Epoch: 969, LR: 0.001000, Loss: 116.7822723\n",
      "Epoch: 970, LR: 0.001000, Loss: 155.0826874\n",
      "Epoch: 971, LR: 0.001000, Loss: 143.6836090\n",
      "Epoch: 972, LR: 0.001000, Loss: 116.6743164\n",
      "Epoch: 973, LR: 0.001000, Loss: 110.7369232\n",
      "Epoch: 974, LR: 0.001000, Loss: 110.5126877\n",
      "Epoch: 975, LR: 0.001000, Loss: 99.4008713\n",
      "Epoch: 976, LR: 0.001000, Loss: 87.5853348\n",
      "Epoch: 977, LR: 0.001000, Loss: 79.8618317\n",
      "Epoch: 978, LR: 0.001000, Loss: 79.9485626\n",
      "Epoch: 979, LR: 0.001000, Loss: 79.4433746\n",
      "Epoch: 980, LR: 0.001000, Loss: 70.5978470\n",
      "Epoch: 981, LR: 0.001000, Loss: 60.2157478\n",
      "Epoch: 982, LR: 0.001000, Loss: 56.6531029\n",
      "Epoch: 983, LR: 0.001000, Loss: 56.8528824\n",
      "Epoch: 984, LR: 0.001000, Loss: 54.6723862\n",
      "Epoch: 985, LR: 0.001000, Loss: 49.7692451\n",
      "Epoch: 986, LR: 0.001000, Loss: 46.0539703\n",
      "Epoch: 987, LR: 0.001000, Loss: 44.4434128\n",
      "Epoch: 988, LR: 0.001000, Loss: 43.6114998\n",
      "Epoch: 989, LR: 0.001000, Loss: 40.4309044\n",
      "Epoch: 990, LR: 0.001000, Loss: 34.3689880\n",
      "Epoch: 991, LR: 0.001000, Loss: 30.1133404\n",
      "Epoch: 992, LR: 0.001000, Loss: 28.0471153\n",
      "Epoch: 993, LR: 0.001000, Loss: 24.9144363\n",
      "Epoch: 994, LR: 0.001000, Loss: 23.7491035\n",
      "Epoch: 995, LR: 0.001000, Loss: 20.7585678\n",
      "Epoch: 996, LR: 0.001000, Loss: 18.4609013\n",
      "Epoch: 997, LR: 0.001000, Loss: 16.6616917\n",
      "Epoch: 998, LR: 0.001000, Loss: 13.7899733\n",
      "Epoch: 999, LR: 0.001000, Loss: 12.8979712\n",
      "Epoch: 1000, LR: 0.001000, Loss: 11.2314701\n",
      "Epoch: 1001, LR: 0.001000, Loss: 9.1542015\n",
      "Epoch: 1002, LR: 0.001000, Loss: 8.4170532\n",
      "Epoch: 1003, LR: 0.001000, Loss: 7.0907640\n",
      "Epoch: 1004, LR: 0.001000, Loss: 5.8279023\n",
      "Epoch: 1005, LR: 0.001000, Loss: 5.3818016\n",
      "Epoch: 1006, LR: 0.001000, Loss: 4.3991337\n",
      "Epoch: 1007, LR: 0.001000, Loss: 4.1964698\n",
      "Epoch: 1008, LR: 0.001000, Loss: 3.2716236\n",
      "Epoch: 1009, LR: 0.001000, Loss: 3.0704393\n",
      "Epoch: 1010, LR: 0.001000, Loss: 2.5916381\n",
      "Epoch: 1011, LR: 0.001000, Loss: 2.2147315\n",
      "Epoch: 1012, LR: 0.001000, Loss: 2.1830561\n",
      "Epoch: 1013, LR: 0.001000, Loss: 1.6256258\n",
      "Epoch: 1014, LR: 0.001000, Loss: 1.5764123\n",
      "Epoch: 1015, LR: 0.001000, Loss: 1.1839644\n",
      "Epoch: 1016, LR: 0.001000, Loss: 1.1879182\n",
      "Epoch: 1017, LR: 0.001000, Loss: 0.9029850\n",
      "Epoch: 1018, LR: 0.001000, Loss: 0.9410937\n",
      "Epoch: 1019, LR: 0.001000, Loss: 0.8194118\n",
      "Epoch: 1020, LR: 0.001000, Loss: 0.6969792\n",
      "Epoch: 1021, LR: 0.001000, Loss: 0.6623573\n",
      "Epoch: 1022, LR: 0.001000, Loss: 0.4999181\n",
      "Epoch: 1023, LR: 0.001000, Loss: 0.4860716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1024, LR: 0.001000, Loss: 0.3734351\n",
      "Epoch: 1025, LR: 0.001000, Loss: 0.4177614\n",
      "Epoch: 1026, LR: 0.001000, Loss: 0.2991917\n",
      "Epoch: 1027, LR: 0.001000, Loss: 0.3649381\n",
      "Epoch: 1028, LR: 0.001000, Loss: 0.2734947\n",
      "Epoch: 1029, LR: 0.001000, Loss: 0.2991608\n",
      "Epoch: 1030, LR: 0.001000, Loss: 0.2212166\n",
      "Epoch: 1031, LR: 0.001000, Loss: 0.2364379\n",
      "Epoch: 1032, LR: 0.001000, Loss: 0.1608180\n",
      "Epoch: 1033, LR: 0.001000, Loss: 0.1848759\n",
      "Epoch: 1034, LR: 0.001000, Loss: 0.1477481\n",
      "Epoch: 1035, LR: 0.001000, Loss: 0.1537188\n",
      "Epoch: 1036, LR: 0.001000, Loss: 0.1322937\n",
      "Epoch: 1037, LR: 0.001000, Loss: 0.1318352\n",
      "Epoch: 1038, LR: 0.001000, Loss: 0.1114603\n",
      "Epoch: 1039, LR: 0.001000, Loss: 0.1112225\n",
      "Epoch: 1040, LR: 0.001000, Loss: 0.1069954\n",
      "Epoch: 1041, LR: 0.001000, Loss: 0.0956261\n",
      "Epoch: 1042, LR: 0.001000, Loss: 0.0981821\n",
      "Epoch: 1043, LR: 0.001000, Loss: 0.0896367\n",
      "Epoch: 1044, LR: 0.001000, Loss: 0.0926855\n",
      "Epoch: 1045, LR: 0.001000, Loss: 0.0861868\n",
      "Epoch: 1046, LR: 0.001000, Loss: 0.0929396\n",
      "Epoch: 1047, LR: 0.001000, Loss: 0.0805304\n",
      "Epoch: 1048, LR: 0.001000, Loss: 0.0861415\n",
      "Epoch: 1049, LR: 0.001000, Loss: 0.0765686\n",
      "Epoch: 1050, LR: 0.001000, Loss: 0.0782996\n",
      "Epoch: 1051, LR: 0.001000, Loss: 0.0695479\n",
      "Epoch: 1052, LR: 0.001000, Loss: 0.0716299\n",
      "Epoch: 1053, LR: 0.001000, Loss: 0.0629103\n",
      "Epoch: 1054, LR: 0.001000, Loss: 0.0651720\n",
      "Epoch: 1055, LR: 0.001000, Loss: 0.0607977\n",
      "Epoch: 1056, LR: 0.001000, Loss: 0.0616679\n",
      "Epoch: 1057, LR: 0.001000, Loss: 0.0560175\n",
      "Epoch: 1058, LR: 0.001000, Loss: 0.0561980\n",
      "Epoch: 1059, LR: 0.001000, Loss: 0.0499404\n",
      "Epoch: 1060, LR: 0.001000, Loss: 0.0508165\n",
      "Epoch: 1061, LR: 0.001000, Loss: 0.0463717\n",
      "Epoch: 1062, LR: 0.001000, Loss: 0.0455972\n",
      "Epoch: 1063, LR: 0.001000, Loss: 0.0430086\n",
      "Epoch: 1064, LR: 0.001000, Loss: 0.0422519\n",
      "Epoch: 1065, LR: 0.001000, Loss: 0.0393034\n",
      "Epoch: 1066, LR: 0.001000, Loss: 0.0385163\n",
      "Epoch: 1067, LR: 0.001000, Loss: 0.0361957\n",
      "Epoch: 1068, LR: 0.001000, Loss: 0.0345351\n",
      "Epoch: 1069, LR: 0.001000, Loss: 0.0330791\n",
      "Epoch: 1070, LR: 0.001000, Loss: 0.0318578\n",
      "Epoch: 1071, LR: 0.001000, Loss: 0.0301479\n",
      "Epoch: 1072, LR: 0.001000, Loss: 0.0292007\n",
      "Epoch: 1073, LR: 0.001000, Loss: 0.0281049\n",
      "Epoch: 1074, LR: 0.001000, Loss: 0.0268227\n",
      "Epoch: 1075, LR: 0.001000, Loss: 0.0259686\n",
      "Epoch: 1076, LR: 0.001000, Loss: 0.0248189\n",
      "Epoch: 1077, LR: 0.001000, Loss: 0.0237029\n",
      "Epoch: 1078, LR: 0.001000, Loss: 0.0227031\n",
      "Epoch: 1079, LR: 0.001000, Loss: 0.0219752\n",
      "Epoch: 1080, LR: 0.001000, Loss: 0.0208898\n",
      "Epoch: 1081, LR: 0.001000, Loss: 0.0203055\n",
      "Epoch: 1082, LR: 0.001000, Loss: 0.0194472\n",
      "Epoch: 1083, LR: 0.001000, Loss: 0.0187999\n",
      "Epoch: 1084, LR: 0.001000, Loss: 0.0180396\n",
      "Epoch: 1085, LR: 0.001000, Loss: 0.0175287\n",
      "Epoch: 1086, LR: 0.001000, Loss: 0.0166754\n",
      "Epoch: 1087, LR: 0.001000, Loss: 0.0162037\n",
      "Epoch: 1088, LR: 0.001000, Loss: 0.0155234\n",
      "Epoch: 1089, LR: 0.001000, Loss: 0.0150520\n",
      "Epoch: 1090, LR: 0.001000, Loss: 0.0144471\n",
      "Epoch: 1091, LR: 0.001000, Loss: 0.0140526\n",
      "Epoch: 1092, LR: 0.001000, Loss: 0.0134239\n",
      "Epoch: 1093, LR: 0.001000, Loss: 0.0130437\n",
      "Epoch: 1094, LR: 0.001000, Loss: 0.0125056\n",
      "Epoch: 1095, LR: 0.001000, Loss: 0.0121017\n",
      "Epoch: 1096, LR: 0.001000, Loss: 0.0116042\n",
      "Epoch: 1097, LR: 0.001000, Loss: 0.0112581\n",
      "Epoch: 1098, LR: 0.001000, Loss: 0.0107836\n",
      "Epoch: 1099, LR: 0.001000, Loss: 0.0104651\n",
      "Epoch: 1100, LR: 0.001000, Loss: 0.0100565\n",
      "Epoch: 1101, LR: 0.001000, Loss: 0.0097323\n",
      "Epoch: 1102, LR: 0.001000, Loss: 0.0093569\n",
      "Epoch: 1103, LR: 0.001000, Loss: 0.0090683\n",
      "Epoch: 1104, LR: 0.001000, Loss: 0.0087081\n",
      "Epoch: 1105, LR: 0.001000, Loss: 0.0084328\n",
      "Epoch: 1106, LR: 0.001000, Loss: 0.0081122\n",
      "Epoch: 1107, LR: 0.001000, Loss: 0.0078425\n",
      "Epoch: 1108, LR: 0.001000, Loss: 0.0075494\n",
      "Epoch: 1109, LR: 0.001000, Loss: 0.0073034\n",
      "Epoch: 1110, LR: 0.001000, Loss: 0.0070216\n",
      "Epoch: 1111, LR: 0.001000, Loss: 0.0067875\n",
      "Epoch: 1112, LR: 0.001000, Loss: 0.0065333\n",
      "Epoch: 1113, LR: 0.001000, Loss: 0.0063068\n",
      "Epoch: 1114, LR: 0.001000, Loss: 0.0060720\n",
      "Epoch: 1115, LR: 0.001000, Loss: 0.0058640\n",
      "Epoch: 1116, LR: 0.001000, Loss: 0.0056424\n",
      "Epoch: 1117, LR: 0.001000, Loss: 0.0054503\n",
      "Epoch: 1118, LR: 0.001000, Loss: 0.0052504\n",
      "Epoch: 1119, LR: 0.001000, Loss: 0.0050672\n",
      "Epoch: 1120, LR: 0.001000, Loss: 0.0048824\n",
      "Epoch: 1121, LR: 0.001000, Loss: 0.0047125\n",
      "Epoch: 1122, LR: 0.001000, Loss: 0.0045390\n",
      "Epoch: 1123, LR: 0.001000, Loss: 0.0043826\n",
      "Epoch: 1124, LR: 0.001000, Loss: 0.0042234\n",
      "Epoch: 1125, LR: 0.001000, Loss: 0.0040756\n",
      "Epoch: 1126, LR: 0.001000, Loss: 0.0039289\n",
      "Epoch: 1127, LR: 0.001000, Loss: 0.0037912\n",
      "Epoch: 1128, LR: 0.001000, Loss: 0.0036535\n",
      "Epoch: 1129, LR: 0.001000, Loss: 0.0035261\n",
      "Epoch: 1130, LR: 0.001000, Loss: 0.0033979\n",
      "Epoch: 1131, LR: 0.001000, Loss: 0.0032778\n",
      "Epoch: 1132, LR: 0.001000, Loss: 0.0031596\n",
      "Epoch: 1133, LR: 0.001000, Loss: 0.0030477\n",
      "Epoch: 1134, LR: 0.001000, Loss: 0.0029370\n",
      "Epoch: 1135, LR: 0.001000, Loss: 0.0028332\n",
      "Epoch: 1136, LR: 0.001000, Loss: 0.0027304\n",
      "Epoch: 1137, LR: 0.001000, Loss: 0.0026332\n",
      "Epoch: 1138, LR: 0.001000, Loss: 0.0025381\n",
      "Epoch: 1139, LR: 0.001000, Loss: 0.0024476\n",
      "Epoch: 1140, LR: 0.001000, Loss: 0.0023590\n",
      "Epoch: 1141, LR: 0.001000, Loss: 0.0022749\n",
      "Epoch: 1142, LR: 0.001000, Loss: 0.0021921\n",
      "Epoch: 1143, LR: 0.001000, Loss: 0.0021140\n",
      "Epoch: 1144, LR: 0.001000, Loss: 0.0020373\n",
      "Epoch: 1145, LR: 0.001000, Loss: 0.0019641\n",
      "Epoch: 1146, LR: 0.001000, Loss: 0.0018929\n",
      "Epoch: 1147, LR: 0.001000, Loss: 0.0018248\n",
      "Epoch: 1148, LR: 0.001000, Loss: 0.0017581\n",
      "Epoch: 1149, LR: 0.001000, Loss: 0.0016943\n",
      "Epoch: 1150, LR: 0.001000, Loss: 0.0016320\n",
      "Epoch: 1151, LR: 0.001000, Loss: 0.0015723\n",
      "Epoch: 1152, LR: 0.001000, Loss: 0.0015144\n",
      "Epoch: 1153, LR: 0.001000, Loss: 0.0014587\n",
      "Epoch: 1154, LR: 0.001000, Loss: 0.0014047\n",
      "Epoch: 1155, LR: 0.001000, Loss: 0.0013527\n",
      "Epoch: 1156, LR: 0.001000, Loss: 0.0013021\n",
      "Epoch: 1157, LR: 0.001000, Loss: 0.0012534\n",
      "Epoch: 1158, LR: 0.001000, Loss: 0.0012064\n",
      "Epoch: 1159, LR: 0.001000, Loss: 0.0011610\n",
      "Epoch: 1160, LR: 0.001000, Loss: 0.0011173\n",
      "Epoch: 1161, LR: 0.001000, Loss: 0.0010749\n",
      "Epoch: 1162, LR: 0.001000, Loss: 0.0010341\n",
      "Epoch: 1163, LR: 0.001000, Loss: 0.0009945\n",
      "Epoch: 1164, LR: 0.001000, Loss: 0.0009565\n",
      "Epoch: 1165, LR: 0.001000, Loss: 0.0009198\n",
      "Epoch: 1166, LR: 0.001000, Loss: 0.0008843\n",
      "Epoch: 1167, LR: 0.001000, Loss: 0.0008501\n",
      "Epoch: 1168, LR: 0.001000, Loss: 0.0008172\n",
      "Epoch: 1169, LR: 0.001000, Loss: 0.0007853\n",
      "Epoch: 1170, LR: 0.001000, Loss: 0.0007547\n",
      "Epoch: 1171, LR: 0.001000, Loss: 0.0007252\n",
      "Epoch: 1172, LR: 0.001000, Loss: 0.0006967\n",
      "Epoch: 1173, LR: 0.001000, Loss: 0.0006692\n",
      "Epoch: 1174, LR: 0.001000, Loss: 0.0006427\n",
      "Epoch: 1175, LR: 0.001000, Loss: 0.0006174\n",
      "Epoch: 1176, LR: 0.001000, Loss: 0.0005927\n",
      "Epoch: 1177, LR: 0.001000, Loss: 0.0005691\n",
      "Epoch: 1178, LR: 0.001000, Loss: 0.0005463\n",
      "Epoch: 1179, LR: 0.001000, Loss: 0.0005245\n",
      "Epoch: 1180, LR: 0.001000, Loss: 0.0005033\n",
      "Epoch: 1181, LR: 0.001000, Loss: 0.0004830\n",
      "Epoch: 1182, LR: 0.001000, Loss: 0.0004636\n",
      "Epoch: 1183, LR: 0.001000, Loss: 0.0004448\n",
      "Epoch: 1184, LR: 0.001000, Loss: 0.0004268\n",
      "Epoch: 1185, LR: 0.001000, Loss: 0.0004092\n",
      "Epoch: 1186, LR: 0.001000, Loss: 0.0003927\n",
      "Epoch: 1187, LR: 0.001000, Loss: 0.0003765\n",
      "Epoch: 1188, LR: 0.001000, Loss: 0.0003611\n",
      "Epoch: 1189, LR: 0.001000, Loss: 0.0003462\n",
      "Epoch: 1190, LR: 0.001000, Loss: 0.0003319\n",
      "Epoch: 1191, LR: 0.001000, Loss: 0.0003180\n",
      "Epoch: 1192, LR: 0.001000, Loss: 0.0003050\n",
      "Epoch: 1193, LR: 0.001000, Loss: 0.0002922\n",
      "Epoch: 1194, LR: 0.001000, Loss: 0.0002801\n",
      "Epoch: 1195, LR: 0.001000, Loss: 0.0002684\n",
      "Epoch: 1196, LR: 0.001000, Loss: 0.0002571\n",
      "Epoch: 1197, LR: 0.001000, Loss: 0.0002463\n",
      "Epoch: 1198, LR: 0.001000, Loss: 0.0002360\n",
      "Epoch: 1199, LR: 0.001000, Loss: 0.0002259\n",
      "Epoch: 1200, LR: 0.001000, Loss: 0.0002165\n",
      "Epoch: 1201, LR: 0.001000, Loss: 0.0002074\n",
      "Epoch: 1202, LR: 0.001000, Loss: 0.0001986\n",
      "Epoch: 1203, LR: 0.001000, Loss: 0.0001901\n",
      "Epoch: 1204, LR: 0.001000, Loss: 0.0001820\n",
      "Epoch: 1205, LR: 0.001000, Loss: 0.0001743\n",
      "Epoch: 1206, LR: 0.001000, Loss: 0.0001669\n",
      "Epoch: 1207, LR: 0.001000, Loss: 0.0001597\n",
      "Epoch: 1208, LR: 0.001000, Loss: 0.0001528\n",
      "Epoch: 1209, LR: 0.001000, Loss: 0.0001462\n",
      "Epoch: 1210, LR: 0.001000, Loss: 0.0001399\n",
      "Epoch: 1211, LR: 0.001000, Loss: 0.0001338\n",
      "Epoch: 1212, LR: 0.001000, Loss: 0.0001281\n",
      "Epoch: 1213, LR: 0.001000, Loss: 0.0001226\n",
      "Epoch: 1214, LR: 0.001000, Loss: 0.0001173\n",
      "Epoch: 1215, LR: 0.001000, Loss: 0.0001122\n",
      "Epoch: 1216, LR: 0.001000, Loss: 0.0001073\n",
      "Epoch: 1217, LR: 0.001000, Loss: 0.0001027\n",
      "Epoch: 1218, LR: 0.001000, Loss: 0.0000982\n",
      "Epoch: 1219, LR: 0.001000, Loss: 0.0000938\n",
      "Epoch: 1220, LR: 0.001000, Loss: 0.0000898\n",
      "Epoch: 1221, LR: 0.001000, Loss: 0.0000858\n",
      "Epoch: 1222, LR: 0.001000, Loss: 0.0000820\n",
      "Epoch: 1223, LR: 0.001000, Loss: 0.0000784\n",
      "Epoch: 1224, LR: 0.001000, Loss: 0.0000750\n",
      "Epoch: 1225, LR: 0.001000, Loss: 0.0000717\n",
      "Epoch: 1226, LR: 0.001000, Loss: 0.0000685\n",
      "Epoch: 1227, LR: 0.001000, Loss: 0.0000655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228, LR: 0.001000, Loss: 0.0000626\n",
      "Epoch: 1229, LR: 0.001000, Loss: 0.0000598\n",
      "Epoch: 1230, LR: 0.001000, Loss: 0.0000572\n",
      "Epoch: 1231, LR: 0.001000, Loss: 0.0000547\n",
      "Epoch: 1232, LR: 0.001000, Loss: 0.0000522\n",
      "Epoch: 1233, LR: 0.001000, Loss: 0.0000499\n",
      "Epoch: 1234, LR: 0.001000, Loss: 0.0000476\n",
      "Epoch: 1235, LR: 0.001000, Loss: 0.0000455\n",
      "Epoch: 1236, LR: 0.001000, Loss: 0.0000434\n",
      "Epoch: 1237, LR: 0.001000, Loss: 0.0000415\n",
      "Epoch: 1238, LR: 0.001000, Loss: 0.0000396\n",
      "Epoch: 1239, LR: 0.001000, Loss: 0.0000378\n",
      "Epoch: 1240, LR: 0.001000, Loss: 0.0000361\n",
      "Epoch: 1241, LR: 0.001000, Loss: 0.0000345\n",
      "Epoch: 1242, LR: 0.001000, Loss: 0.0000329\n",
      "Epoch: 1243, LR: 0.001000, Loss: 0.0000315\n",
      "Epoch: 1244, LR: 0.001000, Loss: 0.0000300\n",
      "Epoch: 1245, LR: 0.001000, Loss: 0.0000287\n",
      "Epoch: 1246, LR: 0.001000, Loss: 0.0000274\n",
      "Epoch: 1247, LR: 0.001000, Loss: 0.0000261\n",
      "Epoch: 1248, LR: 0.001000, Loss: 0.0000250\n",
      "Epoch: 1249, LR: 0.001000, Loss: 0.0000238\n",
      "Epoch: 1250, LR: 0.001000, Loss: 0.0000227\n",
      "Epoch: 1251, LR: 0.001000, Loss: 0.0000217\n",
      "Epoch: 1252, LR: 0.001000, Loss: 0.0000207\n",
      "Epoch: 1253, LR: 0.001000, Loss: 0.0000197\n",
      "Epoch: 1254, LR: 0.001000, Loss: 0.0000188\n",
      "Epoch: 1255, LR: 0.001000, Loss: 0.0000180\n",
      "Epoch: 1256, LR: 0.001000, Loss: 0.0000171\n",
      "Epoch: 1257, LR: 0.001000, Loss: 0.0000164\n",
      "Epoch: 1258, LR: 0.001000, Loss: 0.0000156\n",
      "Epoch: 1259, LR: 0.001000, Loss: 0.0000149\n",
      "Epoch: 1260, LR: 0.001000, Loss: 0.0000142\n",
      "Epoch: 1261, LR: 0.001000, Loss: 0.0000136\n",
      "Epoch: 1262, LR: 0.001000, Loss: 0.0000129\n",
      "Epoch: 1263, LR: 0.001000, Loss: 0.0000123\n",
      "Epoch: 1264, LR: 0.001000, Loss: 0.0000117\n",
      "Epoch: 1265, LR: 0.001000, Loss: 0.0000112\n",
      "Epoch: 1266, LR: 0.001000, Loss: 0.0000107\n",
      "Epoch: 1267, LR: 0.001000, Loss: 0.0000102\n",
      "Epoch: 1268, LR: 0.001000, Loss: 0.0000097\n",
      "Epoch: 1269, LR: 0.001000, Loss: 0.0000093\n",
      "Epoch: 1270, LR: 0.001000, Loss: 0.0000088\n",
      "Epoch: 1271, LR: 0.001000, Loss: 0.0000084\n",
      "Epoch: 1272, LR: 0.001000, Loss: 0.0000080\n",
      "Epoch: 1273, LR: 0.001000, Loss: 0.0000077\n",
      "Epoch: 1274, LR: 0.001000, Loss: 0.0000073\n",
      "Epoch: 1275, LR: 0.001000, Loss: 0.0000069\n",
      "Epoch: 1276, LR: 0.001000, Loss: 0.0000066\n",
      "Epoch: 1277, LR: 0.001000, Loss: 0.0000063\n",
      "Epoch: 1278, LR: 0.001000, Loss: 0.0000060\n",
      "Epoch: 1279, LR: 0.001000, Loss: 0.0000058\n",
      "Epoch: 1280, LR: 0.001000, Loss: 0.0000055\n",
      "Epoch: 1281, LR: 0.001000, Loss: 0.0000052\n",
      "Epoch: 1282, LR: 0.001000, Loss: 0.0000050\n",
      "Epoch: 1283, LR: 0.001000, Loss: 0.0000047\n",
      "Epoch: 1284, LR: 0.001000, Loss: 0.0000045\n",
      "Epoch: 1285, LR: 0.001000, Loss: 0.0000043\n",
      "Epoch: 1286, LR: 0.001000, Loss: 0.0000041\n",
      "Epoch: 1287, LR: 0.001000, Loss: 0.0000039\n",
      "Epoch: 1288, LR: 0.001000, Loss: 0.0000037\n",
      "Epoch: 1289, LR: 0.001000, Loss: 0.0000035\n",
      "Epoch: 1290, LR: 0.001000, Loss: 0.0000034\n",
      "Epoch: 1291, LR: 0.001000, Loss: 0.0000032\n",
      "Epoch: 1292, LR: 0.001000, Loss: 0.0000031\n",
      "Epoch: 1293, LR: 0.001000, Loss: 0.0000029\n",
      "Epoch: 1294, LR: 0.001000, Loss: 0.0000028\n",
      "Epoch: 1295, LR: 0.001000, Loss: 0.0000026\n",
      "Epoch: 1296, LR: 0.001000, Loss: 0.0000025\n",
      "Epoch: 1297, LR: 0.001000, Loss: 0.0000024\n",
      "Epoch: 1298, LR: 0.001000, Loss: 0.0000023\n",
      "Epoch: 1299, LR: 0.001000, Loss: 0.0000022\n",
      "Epoch: 1300, LR: 0.001000, Loss: 0.0000021\n",
      "Epoch: 1301, LR: 0.001000, Loss: 0.0000020\n",
      "Epoch: 1302, LR: 0.001000, Loss: 0.0000019\n",
      "Epoch: 1303, LR: 0.001000, Loss: 0.0000018\n",
      "Epoch: 1304, LR: 0.001000, Loss: 0.0000017\n",
      "Epoch: 1305, LR: 0.001000, Loss: 0.0000016\n",
      "Epoch: 1306, LR: 0.001000, Loss: 0.0000016\n",
      "Epoch: 1307, LR: 0.001000, Loss: 0.0000015\n",
      "Epoch: 1308, LR: 0.001000, Loss: 0.0000014\n",
      "Epoch: 1309, LR: 0.001000, Loss: 0.0000013\n",
      "Epoch: 1310, LR: 0.001000, Loss: 0.0000013\n",
      "Epoch: 1311, LR: 0.001000, Loss: 0.0000012\n",
      "Epoch: 1312, LR: 0.001000, Loss: 0.0000012\n",
      "Epoch: 1313, LR: 0.001000, Loss: 0.0000011\n",
      "Epoch: 1314, LR: 0.001000, Loss: 0.0000011\n",
      "Epoch: 1315, LR: 0.001000, Loss: 0.0000010\n",
      "Epoch: 1316, LR: 0.001000, Loss: 0.0000010\n",
      "Epoch: 1317, LR: 0.001000, Loss: 0.0000009\n",
      "Epoch: 1318, LR: 0.001000, Loss: 0.0000009\n",
      "Epoch: 1319, LR: 0.001000, Loss: 0.0000008\n",
      "Epoch: 1320, LR: 0.001000, Loss: 0.0000008\n",
      "Epoch: 1321, LR: 0.001000, Loss: 0.0000007\n",
      "Epoch: 1322, LR: 0.001000, Loss: 0.0000007\n",
      "Epoch: 1323, LR: 0.001000, Loss: 0.0000007\n",
      "Epoch: 1324, LR: 0.001000, Loss: 0.0000006\n",
      "Epoch: 1325, LR: 0.001000, Loss: 0.0000006\n",
      "Epoch: 1326, LR: 0.001000, Loss: 0.0000006\n",
      "Epoch: 1327, LR: 0.001000, Loss: 0.0000006\n",
      "Epoch: 1328, LR: 0.001000, Loss: 0.0000005\n",
      "Epoch: 1329, LR: 0.001000, Loss: 0.0000005\n",
      "Epoch: 1330, LR: 0.001000, Loss: 0.0000005\n",
      "Epoch: 1331, LR: 0.001000, Loss: 0.0000005\n",
      "Epoch: 1332, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 1333, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 1334, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 1335, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 1336, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 1337, LR: 0.001000, Loss: 0.0000004\n",
      "Epoch: 1338, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 1339, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 1340, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 1341, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 1342, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 1343, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 1344, LR: 0.001000, Loss: 0.0000003\n",
      "Epoch: 1345, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 1346, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 1347, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 1348, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 1349, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 1350, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 1351, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 1352, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 1353, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 1354, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 1355, LR: 0.001000, Loss: 0.0000002\n",
      "Epoch: 1356, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1357, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1358, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1359, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1360, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1361, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1362, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1363, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1364, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1365, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1366, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1367, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1368, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1369, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1370, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1371, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1372, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1373, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1374, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1375, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1376, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1377, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1378, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1379, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1380, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1381, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1382, LR: 0.001000, Loss: 0.0000001\n",
      "Epoch: 1383, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1384, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1385, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1386, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1387, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1388, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1389, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1390, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1391, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1392, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1393, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1394, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1395, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1396, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1397, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1398, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1399, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1400, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1401, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1402, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1403, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1404, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1405, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1406, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1407, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1408, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1409, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1410, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1411, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1412, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1413, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1414, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1415, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1416, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1417, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1418, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1419, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1420, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1421, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1422, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1423, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1424, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1425, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1426, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1427, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1428, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1429, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1430, LR: 0.001000, Loss: 0.0000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1431, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1432, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1433, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1434, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1435, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1436, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1437, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1438, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1439, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1440, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1441, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1442, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1443, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1444, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1445, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1446, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1447, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1448, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1449, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1450, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1451, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1452, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1453, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1454, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1455, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1456, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1457, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1458, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1459, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1460, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1461, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1462, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1463, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1464, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1465, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1466, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1467, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1468, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1469, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1470, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1471, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1472, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1473, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1474, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1475, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1476, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1477, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1478, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1479, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1480, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1481, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1482, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1483, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1484, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1485, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1486, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1487, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1488, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1489, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1490, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1491, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1492, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1493, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1494, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1495, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1496, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1497, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1498, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1499, LR: 0.001000, Loss: 0.0000000\n",
      "Epoch: 1500, LR: 0.001000, Loss: 0.0000000\n"
     ]
    }
   ],
   "source": [
    "best_val_error = None\n",
    "for epoch in range(1, 1501):\n",
    "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "    loss = train(epoch)\n",
    "    print('Epoch: {:03d}, LR: {:7f}, Loss: {:.7f}'.format(epoch, lr, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtual Env py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
